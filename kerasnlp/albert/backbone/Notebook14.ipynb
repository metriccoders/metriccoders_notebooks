{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0rOJSwUaOrV",
        "outputId": "07fd3069-d182-4ac9-9c8d-c6c323e93b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (4.66.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2023.11.17)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.23.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.62.0)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_nlp\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_datasets\n",
        "!pip install tensorflow-text\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "import tensorflow_datasets\n",
        "import keras\n",
        "from keras_nlp.models import AlbertTokenizer, AlbertPreprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAJUyqWgaXmo",
        "outputId": "69aaf31d-dc29-4e1b-bba4-4bef5ab27a60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer.from_preset(\"albert_base_en_uncased\",)"
      ],
      "metadata": {
        "id": "buH7ZYIbalZ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize([\"Goat is good\", \"Sheep is good\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUHHP23gaydB",
        "outputId": "00e4a72e-d3fa-4ade-ecc8-aba7fab87a05"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[13, 1, 111, 721, 25, 254],\n",
              " [13, 1, 438, 3492, 25, 254]]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "s2oAYQoRJ6tA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bytes_io = io.BytesIO()"
      ],
      "metadata": {
        "id": "FyWTrq4JJxD4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJXkTosZJzcj",
        "outputId": "418ed22a-72b5-4b70-8c00-14f1c4d9ce75"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "h0QLddZFJ3Gh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([\"The goat was huge\"])"
      ],
      "metadata": {
        "id": "e8iwwi-vJ7yT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2yxmBaYKGul",
        "outputId": "159740ff-c1e2-4116-d66f-165472660afa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "vNumqghFKirN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator=ds.as_numpy_iterator(),\n",
        "    model_writer = bytes_io,\n",
        "    vocab_size=9,\n",
        "    model_type=\"WORD\",\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    pad_piece=\"<pad>\",\n",
        "    unk_piece=\"<unk>\",\n",
        "    bos_piece=\"[CLS]\",\n",
        "    eos_piece=\"[SEP]\",\n",
        "    user_defined_symbols=\"[MASK]\",\n",
        ")"
      ],
      "metadata": {
        "id": "cbR2U5rEKm34"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer(proto=bytes_io.getvalue())"
      ],
      "metadata": {
        "id": "a3xo3hl1LNUM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"The goat is a masterpiece\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeDDwG0BLTe5",
        "outputId": "6252524e-096d-4f4c-eb73-12962c49d596"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 6, 1], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor.from_preset(\"albert_base_en_uncased\")"
      ],
      "metadata": {
        "id": "0IwYYP3zHLom"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"What a game!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sBa3p4CHR7f",
        "outputId": "c78b6e1a-a124-445a-9cdb-2bacdcc87e87"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([   2,   13,    1, 6775,   21,  250,  187,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The quick fox jumped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KqNQ_ouHvqS",
        "outputId": "7160e690-ac6a-4256-e62c-6e6892576799"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([   2,   13,    1,  438, 2231, 2385, 4298,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor([\"Is the goat good?\", \"Is the cow big?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-3J3K_fH1zL",
        "outputId": "2cc1de28-3a7e-46df-ca91-c42c2008e99a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
              " array([[ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0]], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(2, 512), dtype=bool, numpy=\n",
              " array([[ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor([\"What a cow?\", \"Is that a rabbit?\", \"Is this a tiger?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In_3SYy7I3Bq",
        "outputId": "34a26437-730c-490a-d81b-3f9b40ce0951"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
              " array([[ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0]], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(3, 512), dtype=bool, numpy=\n",
              " array([[ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor(tokenizer)"
      ],
      "metadata": {
        "id": "2vCVLvY_JCug"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The goat is a masterpiece\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HvjdZRfJIiK",
        "outputId": "10350294-861d-4f59-8aec-677ae16c4d15"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([2, 5, 6, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bytes_io = io.BytesIO()"
      ],
      "metadata": {
        "id": "1EG7wcImJOEg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([\"The story is interesting\"])"
      ],
      "metadata": {
        "id": "47L4itc0JeWv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator = ds.as_numpy_iterator(),\n",
        "    model_writer= bytes_io,\n",
        "    vocab_size=9,\n",
        "    model_type=\"WORD\",\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    pad_piece=\"<pad>\",\n",
        "    unk_piece=\"<unk>\",\n",
        "    bos_piece=\"[CLS]\",\n",
        "    eos_piece=\"[SEP]\",\n",
        "    user_defined_symbols=\"[MASK]\"\n",
        ")"
      ],
      "metadata": {
        "id": "nGhsg4xfJkRm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer(proto=bytes_io.getvalue(),)"
      ],
      "metadata": {
        "id": "kGVhJqmbJ_iV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor(tokenizer)"
      ],
      "metadata": {
        "id": "1EM-Yk__KIxS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The story is interesting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3J0_E4TKL2L",
        "outputId": "9c079342-f4ab-4834-ac6e-bcb0608222ed"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([2, 5, 8, 7, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first = tf.constant([\"The story is interesting\", \"the story is a mystery\"])"
      ],
      "metadata": {
        "id": "404J3YfVKOoh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second = tf.constant([\"The story looks interesting and cool\", \"Is that a phone?\"])"
      ],
      "metadata": {
        "id": "7M_rkFuDLcax"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tf.constant([1, 1])"
      ],
      "metadata": {
        "id": "6DcfLdrzLjXG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Map labeled single sentence\n",
        "ds = tf.data.Dataset.from_tensor_slices((first, label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ObjjIioyLlNN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices(first)\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "IBGuwfi3Lo5S"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices(((first, second), label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7v7FMR1CL83l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices((first, second))"
      ],
      "metadata": {
        "id": "1z7P0tIJMM8N"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(lambda first, second: preprocessor(x=(first, second)), num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "KvDvx421MWmI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOP4EjaOMfeG",
        "outputId": "2ff663d0-638b-4142-bd67-71bcb35f72d8"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec={'token_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'segment_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(512,), dtype=tf.bool, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "third = tf.constant([\"The game was well played\", \"The game was interesting, isn't it?\"])\n",
        "fourth = tf.constant([\"The fox is quick\", \"The tiger is too quick\"])"
      ],
      "metadata": {
        "id": "hapQ7WaRMhTw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tf.constant([1, 1])"
      ],
      "metadata": {
        "id": "f_S6dZuIPYWU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices((third, fourth))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RoYsAH0RPa17"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices(third)\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "UPYEgTOvPnpb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices(((third, fourth), label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "IPBRYAStPz8b"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices((third, fourth))"
      ],
      "metadata": {
        "id": "OPDvvJxpQDUk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(\n",
        "    lambda third, fourth:preprocessor(x=(third, fourth)),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")"
      ],
      "metadata": {
        "id": "gAyzhwNdQVcO"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpaR3RwXQdfB",
        "outputId": "c6cb9dac-abe4-453b-b9eb-5cba471c6148"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec={'token_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'segment_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(512,), dtype=tf.bool, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_nlp.models import AlbertBackbone"
      ],
      "metadata": {
        "id": "kcczL7RCQ7BA"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "QGG92MXPReC5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),\n",
        "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]),\n",
        "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
        "}"
      ],
      "metadata": {
        "id": "zjltZrRBRpob"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertBackbone(\n",
        "    vocabulary_size=30000,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    num_groups=1,\n",
        "    num_inner_repetitions=1,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=768,\n",
        "    intermediate_dim=3072,\n",
        "    max_sequence_length=12,\n",
        ")"
      ],
      "metadata": {
        "id": "RexVuW0MR7kT"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_data)"
      ],
      "metadata": {
        "id": "fu4LsEQDR-h5"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwB-B_5SAWI",
        "outputId": "b2300622-2fa4-4467-bcf7-3e1ff70bbc50"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence_output': <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              " array([[[ 1.4808228 , -0.06938782,  0.7234533 , ...,  0.4026623 ,\n",
              "          -2.302642  , -1.2570531 ],\n",
              "         [ 1.3868036 ,  0.10428643,  0.68579876, ...,  0.02492731,\n",
              "          -2.048979  , -0.98513925],\n",
              "         [ 1.5992649 , -0.30511796,  0.91260016, ..., -0.25022513,\n",
              "          -1.6114941 , -1.4929962 ],\n",
              "         ...,\n",
              "         [ 1.604283  ,  0.9069713 ,  0.96306974, ..., -0.15491767,\n",
              "          -1.4957494 , -0.6091589 ],\n",
              "         [ 0.9365893 ,  0.26974607,  0.25793144, ..., -0.6287644 ,\n",
              "          -2.1779764 , -1.2142931 ],\n",
              "         [ 1.0742928 , -0.21507901,  0.38710928, ..., -0.24166529,\n",
              "          -1.9188505 , -0.84623885]]], dtype=float32)>,\n",
              " 'pooled_output': <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-1.77859411e-01, -3.22879374e-01, -1.81734622e-01,\n",
              "         -3.20391208e-01,  6.16850078e-01,  1.66342184e-02,\n",
              "         -2.42131222e-02,  4.36578661e-01,  7.34589159e-01,\n",
              "          4.36153740e-01,  1.65401399e-01, -7.43024722e-02,\n",
              "          4.16967601e-01, -3.52592438e-01, -3.11153829e-01,\n",
              "         -1.63927779e-01, -1.23015977e-01, -3.93072397e-01,\n",
              "         -3.24346632e-01,  2.24483043e-01,  2.49296233e-01,\n",
              "          1.29265323e-01,  3.39780509e-01,  5.98109722e-01,\n",
              "          8.76799524e-01, -5.03960431e-01,  3.81608456e-01,\n",
              "         -2.52278447e-01,  1.90163642e-01,  1.06058076e-01,\n",
              "         -8.52146447e-02,  1.53325200e-01, -4.64943856e-01,\n",
              "          6.36085451e-01, -6.21357076e-02,  7.56907523e-01,\n",
              "         -2.82092690e-01, -1.20485067e-01, -3.18666995e-01,\n",
              "         -7.45819747e-01,  2.79704392e-01, -1.62355810e-01,\n",
              "         -3.61879528e-01,  9.81572364e-03,  4.82191116e-01,\n",
              "          3.32385570e-01,  6.48417771e-01, -3.36060822e-01,\n",
              "          7.09735304e-02, -6.21350050e-01, -7.52487719e-01,\n",
              "         -7.61271954e-01, -1.51385546e-01,  2.15241194e-01,\n",
              "         -5.80372810e-01,  2.67760426e-01, -4.58151801e-03,\n",
              "          4.27104414e-01, -1.58396140e-01,  7.18981624e-01,\n",
              "         -1.83547094e-01,  2.35279217e-01,  4.24403042e-01,\n",
              "         -3.62745494e-01, -3.22702080e-01, -4.53914344e-01,\n",
              "         -3.00534338e-01, -3.00627977e-01, -5.95268190e-01,\n",
              "         -6.57938421e-01,  1.98331594e-01,  2.49285221e-01,\n",
              "         -7.42626116e-02,  1.03697613e-01,  3.43478739e-01,\n",
              "         -3.83620530e-01, -5.77666610e-02,  5.39624751e-01,\n",
              "         -9.09359530e-02, -7.88965940e-01,  9.15313587e-02,\n",
              "         -4.32012260e-01, -5.78316934e-02, -2.90990829e-01,\n",
              "         -3.68244708e-01, -7.90943444e-01, -1.78790331e-01,\n",
              "          2.38255896e-02, -3.15941460e-02,  2.55692780e-01,\n",
              "          4.12683517e-01,  8.41446936e-01, -1.99044630e-01,\n",
              "          3.69585484e-01,  2.60034561e-01,  3.41294795e-01,\n",
              "         -5.04939482e-02, -4.23158467e-01,  4.59105134e-01,\n",
              "         -1.71133474e-01,  3.55037004e-01, -1.51139125e-01,\n",
              "          4.70943958e-01, -2.42432579e-01, -3.54095668e-01,\n",
              "          3.15376878e-01, -2.88676232e-01,  4.48141724e-01,\n",
              "         -4.19764161e-01, -4.48675603e-01,  6.57831073e-01,\n",
              "          5.66906750e-01,  1.45198762e-01, -7.01223850e-01,\n",
              "         -1.02245212e-02, -4.44573462e-02, -6.36520565e-01,\n",
              "         -6.14448786e-01,  2.04576269e-01, -4.18417186e-01,\n",
              "         -1.52457476e-01,  8.01146746e-01,  3.11588913e-01,\n",
              "          1.69974461e-01, -3.51560682e-01,  6.20305419e-01,\n",
              "         -1.79879891e-03,  4.31587407e-03,  5.24941921e-01,\n",
              "         -1.12347059e-01, -4.38703775e-01,  5.15815794e-01,\n",
              "         -1.89816922e-01, -3.30162287e-01, -1.98211923e-01,\n",
              "         -1.13946132e-01, -5.99016547e-01, -3.14830929e-01,\n",
              "         -2.47702792e-01, -2.59042025e-01, -2.80724049e-01,\n",
              "          1.10919084e-02, -1.26783803e-01,  1.13570876e-02,\n",
              "          3.47812653e-01,  6.34562001e-02, -2.82574221e-02,\n",
              "          3.67209524e-01,  6.10181391e-01, -3.71313125e-01,\n",
              "          4.45801616e-01, -6.60127044e-01,  2.14797705e-01,\n",
              "         -5.67010224e-01, -2.88715929e-01,  4.16741818e-01,\n",
              "          4.17895228e-01, -3.83762181e-01, -2.23646462e-01,\n",
              "         -2.39174843e-01, -4.01100397e-01, -4.12964523e-01,\n",
              "          1.47654802e-01,  7.82261610e-01, -2.13545650e-01,\n",
              "          5.66672802e-01,  7.64777362e-02, -7.27731436e-02,\n",
              "         -4.56081063e-01, -6.30729079e-01, -2.46240214e-01,\n",
              "         -5.63856840e-01,  4.30430546e-02, -4.15936619e-01,\n",
              "          2.98831046e-01,  8.65767822e-02, -6.28871396e-02,\n",
              "          2.46096343e-01,  6.73373580e-01, -4.52018231e-01,\n",
              "         -1.42119396e-02, -7.84114540e-01, -6.58103108e-01,\n",
              "         -3.83403808e-01,  2.81490423e-02,  6.01391077e-01,\n",
              "         -3.45789760e-01,  2.09624887e-01,  1.01703346e-01,\n",
              "         -8.60601842e-01, -4.66809511e-01, -4.64909434e-01,\n",
              "          5.01392186e-01, -6.33718908e-01,  4.13416997e-02,\n",
              "         -3.66694421e-01,  6.60211384e-01,  5.64745605e-01,\n",
              "         -2.49481350e-02,  4.20359075e-02, -2.06538260e-01,\n",
              "          2.87448436e-01,  6.02763332e-02,  5.28724730e-01,\n",
              "          1.59135804e-01, -5.03502250e-01, -2.44261026e-01,\n",
              "         -2.13107057e-02, -1.51541367e-01, -6.78722262e-01,\n",
              "          2.97628313e-01, -7.34879017e-01, -5.32501712e-02,\n",
              "         -4.81362611e-01, -3.04580212e-01,  2.64322311e-01,\n",
              "          7.33459229e-03,  6.70786574e-03,  1.48603007e-01,\n",
              "         -2.89160281e-01, -4.45205241e-01,  5.00558317e-01,\n",
              "          4.10894990e-01,  9.56241414e-02,  2.94922084e-01,\n",
              "         -8.95700455e-01,  1.04573101e-01, -8.19176197e-01,\n",
              "          4.64144908e-02,  2.32804328e-01, -2.70626098e-01,\n",
              "          7.12546110e-01, -1.34818852e-01, -1.61601976e-01,\n",
              "         -2.90051967e-01, -9.88723189e-02,  3.67270112e-01,\n",
              "          1.31050318e-01,  6.19885147e-01,  4.58965659e-01,\n",
              "          8.88606369e-01, -1.20490380e-01, -1.41360357e-01,\n",
              "         -6.09279573e-01, -2.22572938e-01,  6.35410845e-01,\n",
              "         -4.27277796e-02, -1.80264506e-02, -7.08750486e-01,\n",
              "         -4.19846296e-01, -6.08637393e-01, -1.73258081e-01,\n",
              "         -2.92895585e-01,  4.94542271e-01,  5.43412447e-01,\n",
              "         -3.69737655e-01,  4.84546363e-01,  1.67730495e-01,\n",
              "          5.39963126e-01, -1.51358038e-01,  2.79540390e-01,\n",
              "          1.61286533e-01, -1.88213214e-01, -1.59637451e-01,\n",
              "          1.26145378e-01,  1.54060945e-01,  4.52138066e-01,\n",
              "          2.88047493e-01, -7.46673524e-01, -3.93903017e-01,\n",
              "          3.49940002e-01,  6.02410138e-02, -2.94921130e-01,\n",
              "         -2.73034513e-01, -2.45668903e-01, -1.30038276e-01,\n",
              "          6.53635323e-01, -4.93358999e-01,  7.48784006e-01,\n",
              "          3.37958932e-02,  1.75704449e-01, -1.58194691e-01,\n",
              "          8.29305649e-02,  6.30537391e-01, -9.79853719e-02,\n",
              "         -1.40734702e-01,  2.55366176e-01,  6.69551551e-01,\n",
              "          6.12260044e-01, -2.76538968e-01, -5.67631900e-01,\n",
              "          2.49423772e-01, -6.33811802e-02, -3.92814338e-01,\n",
              "         -1.92607820e-01, -3.43354702e-01,  2.43716404e-01,\n",
              "          6.07264876e-01, -1.95452347e-01,  1.52524943e-02,\n",
              "          4.46016163e-01, -3.17033976e-02,  7.69882083e-01,\n",
              "         -1.70926437e-01,  2.19997019e-01,  5.90968728e-01,\n",
              "          3.45894873e-01, -2.44415015e-01, -2.50252247e-01,\n",
              "          5.55756271e-01,  4.34479713e-01, -2.47171044e-01,\n",
              "          2.16246292e-01, -7.42968917e-01,  3.11714262e-01,\n",
              "         -5.73704898e-01, -3.33153665e-01, -5.50066054e-01,\n",
              "         -3.02639902e-01, -2.26645783e-01,  1.77120760e-01,\n",
              "          2.03377679e-01, -1.68438077e-01, -6.80106997e-01,\n",
              "         -1.43486857e-01, -1.95205227e-01,  1.77608564e-01,\n",
              "          5.43857291e-02, -1.96557958e-02,  1.31221250e-01,\n",
              "         -5.53060234e-01, -3.05579960e-01, -9.80706140e-02,\n",
              "         -3.81518751e-01,  6.04693890e-02,  4.99182850e-01,\n",
              "          6.46455407e-01,  5.07069528e-01, -5.44326343e-02,\n",
              "         -5.15396416e-01,  2.31090677e-03,  2.60862976e-01,\n",
              "          2.64130682e-01, -2.44722366e-01,  4.85536605e-01,\n",
              "          1.64661780e-01,  9.57562104e-02, -3.45608518e-02,\n",
              "         -4.80964631e-01,  1.14258379e-01, -3.28547478e-01,\n",
              "          5.47689915e-01,  4.73180532e-01,  8.23389664e-02,\n",
              "          4.94470030e-01, -4.48780179e-01, -6.38200879e-01,\n",
              "         -3.47957641e-01, -3.52113962e-01,  3.92684519e-01,\n",
              "         -1.11835867e-01,  2.36220941e-01, -7.52732754e-01,\n",
              "         -3.02521348e-01, -9.02522802e-01,  3.29807073e-01,\n",
              "         -6.32980987e-02,  7.05480158e-01, -1.25438660e-01,\n",
              "         -2.63183154e-02, -2.48299018e-01, -1.97512120e-01,\n",
              "         -3.60733390e-01,  1.65627703e-01,  2.41026774e-01,\n",
              "         -2.38025934e-01, -3.74769926e-01, -4.45963025e-01,\n",
              "         -2.35760108e-01, -1.53731436e-01, -6.51854873e-02,\n",
              "         -2.70032525e-01,  4.40963775e-01, -1.78461358e-01,\n",
              "          4.66126889e-01, -6.06567740e-01,  2.99749762e-01,\n",
              "          7.08213300e-02,  2.75417864e-01,  3.08797330e-01,\n",
              "          3.96292388e-01,  4.12926048e-01, -5.31465054e-01,\n",
              "          4.13055778e-01, -2.59452909e-02,  1.33882239e-02,\n",
              "         -2.27372542e-01,  6.71084644e-03, -2.83918321e-01,\n",
              "         -1.43359169e-01,  4.33668852e-01,  5.43063283e-01,\n",
              "         -5.65371275e-01, -6.83120489e-02,  9.02255401e-02,\n",
              "         -5.24695694e-01, -1.72004476e-02, -4.34618890e-01,\n",
              "         -3.91431421e-01,  1.78627253e-01,  1.56432807e-01,\n",
              "          5.52080035e-01, -3.42255563e-01, -4.03536111e-01,\n",
              "          1.67359427e-01, -6.77019775e-01,  5.29029727e-01,\n",
              "         -2.67497063e-01,  4.54294652e-01, -1.46492124e-01,\n",
              "          2.32133582e-01, -2.08476216e-01, -1.48034379e-01,\n",
              "          4.10089046e-01,  4.71189439e-01,  3.17110419e-02,\n",
              "         -1.12678334e-01, -7.15096951e-01, -2.96046585e-02,\n",
              "          5.42914987e-01,  7.06173852e-02,  6.48232460e-01,\n",
              "          1.93280056e-01,  7.97122046e-02, -3.78829002e-01,\n",
              "         -3.11700016e-01, -3.81233901e-01, -6.38286710e-01,\n",
              "         -6.00556195e-01,  3.23840261e-01,  1.35156140e-01,\n",
              "          3.55371356e-01, -6.81471050e-01,  2.82007247e-01,\n",
              "          2.24805325e-02, -1.20445885e-01,  3.40149879e-01,\n",
              "          4.46769953e-01,  2.30312526e-01,  5.21532416e-01,\n",
              "         -4.89614159e-01,  2.32594758e-01,  5.42284369e-01,\n",
              "          6.26126051e-01, -6.36497796e-01, -4.60366070e-01,\n",
              "          1.96210101e-01,  1.28555506e-01, -2.87260801e-01,\n",
              "         -5.14635623e-01,  5.78376472e-01,  1.70079499e-01,\n",
              "         -6.16575062e-01, -3.11138242e-01, -2.49116167e-01,\n",
              "         -7.51713276e-01,  3.13671768e-01,  5.56389093e-01,\n",
              "          1.74633041e-01,  1.85189135e-02, -1.82393640e-02,\n",
              "          4.14356172e-01,  4.64545399e-01,  1.72158822e-01,\n",
              "         -7.38605738e-01,  2.82937229e-01,  1.89389646e-01,\n",
              "          2.85307765e-01, -8.62748563e-01, -1.55566707e-01,\n",
              "         -5.46462536e-01,  2.78197527e-01,  1.67915568e-01,\n",
              "          4.08014208e-01, -4.69469577e-01, -5.97660899e-01,\n",
              "         -4.14373934e-01,  5.03744543e-01, -1.62259609e-01,\n",
              "         -8.77787247e-02, -4.46478784e-01,  4.14461523e-01,\n",
              "          3.84283334e-01, -2.42719099e-01, -2.53527284e-01,\n",
              "          3.92579436e-01,  2.44583413e-01, -1.38417065e-01,\n",
              "         -5.90644121e-01,  5.42008042e-01, -4.70117211e-01,\n",
              "         -4.09888715e-01, -2.76462615e-01, -4.58424360e-01,\n",
              "          4.91941303e-01, -1.91003736e-02, -2.82306731e-01,\n",
              "         -4.71353650e-01,  3.57397497e-02, -1.97232217e-01,\n",
              "         -4.44592595e-01, -1.65130660e-01,  7.85466492e-01,\n",
              "         -3.03521842e-01, -5.64636230e-01, -5.56870818e-01,\n",
              "          4.17125404e-01,  1.52122125e-01, -2.97265537e-02,\n",
              "         -9.07125548e-02,  7.81352758e-01,  6.97411835e-01,\n",
              "          1.89424828e-01, -6.30522370e-01,  7.11668050e-03,\n",
              "         -2.36893326e-01, -8.59401345e-01,  5.20160377e-01,\n",
              "          4.44519788e-01, -2.54737973e-01, -3.18892777e-01,\n",
              "         -3.73440385e-01,  6.31020486e-01, -5.94112158e-01,\n",
              "         -1.40894696e-01, -3.65681887e-01,  3.44280064e-01,\n",
              "          7.49147236e-01, -2.97437191e-01, -2.40761116e-01,\n",
              "         -8.55856165e-02,  3.00908864e-01, -1.54122531e-01,\n",
              "         -7.60947227e-01,  3.86842608e-01,  4.15079445e-01,\n",
              "          1.35169968e-01, -3.71643007e-01, -9.38744470e-02,\n",
              "          7.77764246e-02, -1.30369291e-01,  1.26412496e-01,\n",
              "          5.86381733e-01,  1.19178474e-01,  6.46734774e-01,\n",
              "          3.92517775e-01,  7.54961073e-01, -2.82776561e-02,\n",
              "         -4.65151459e-01,  4.91687536e-01,  4.98293936e-01,\n",
              "          2.39912704e-01, -6.61686659e-02, -1.29429221e-01,\n",
              "          5.31348825e-01,  4.44932342e-01,  1.81995332e-02,\n",
              "         -1.13249093e-01,  4.44722563e-01, -2.41485208e-01,\n",
              "          2.32589003e-02,  5.52884638e-01, -7.34167933e-01,\n",
              "         -3.81811649e-01,  1.58495635e-01,  5.48003078e-01,\n",
              "         -4.18541759e-01, -8.38153362e-01, -2.17191964e-01,\n",
              "         -3.44293624e-01, -4.59734231e-01,  1.00857548e-01,\n",
              "          7.47094214e-01,  3.37100364e-02,  4.66875322e-02,\n",
              "          5.92049956e-01, -2.80933052e-01,  7.41453111e-01,\n",
              "          5.93710244e-01,  3.52303296e-01,  8.14785242e-01,\n",
              "          5.26164889e-01, -3.84111762e-01,  2.73168206e-01,\n",
              "         -1.37723491e-01,  6.57071546e-02, -5.05908243e-02,\n",
              "         -2.60569751e-01,  2.80016094e-01, -6.35325015e-01,\n",
              "          9.43723693e-02, -6.72176242e-01,  7.22934067e-01,\n",
              "          5.74722409e-01, -1.62967622e-01, -5.20358622e-01,\n",
              "          6.65269494e-01, -6.06557906e-01, -5.85576415e-01,\n",
              "          3.89277726e-01,  5.15520394e-01,  4.85630661e-01,\n",
              "          6.57398760e-01,  1.04678974e-01, -3.59153271e-01,\n",
              "         -4.22400445e-01,  4.91735488e-01,  8.84287283e-02,\n",
              "         -5.14607787e-01, -5.48762381e-01, -7.36117661e-01,\n",
              "          6.36300623e-01,  3.61276656e-01,  6.49921238e-01,\n",
              "          6.42306626e-01, -1.41160628e-02, -1.47354811e-01,\n",
              "         -6.58230901e-01, -4.79024440e-01,  1.24264888e-01,\n",
              "         -6.64361656e-01, -1.22500904e-01, -2.23981410e-01,\n",
              "         -2.71594524e-01,  4.75591756e-02,  2.08479419e-01,\n",
              "          2.72774175e-02, -5.43775499e-01, -3.83651882e-01,\n",
              "          3.58192444e-01,  3.84361558e-02, -3.74714881e-01,\n",
              "         -3.38571399e-01, -1.70634001e-01,  2.09098354e-01,\n",
              "         -6.09006941e-01, -2.26478755e-01,  2.92716116e-01,\n",
              "          3.49662751e-01,  4.34618533e-01,  1.67646602e-01,\n",
              "         -1.88776493e-01,  5.34240067e-01,  6.54151201e-01,\n",
              "         -7.53282964e-01, -5.72450995e-01, -6.39925063e-01,\n",
              "         -7.07469106e-01,  3.21906954e-01,  3.89598370e-01,\n",
              "          5.48241019e-01, -3.96833234e-02,  4.88017052e-01,\n",
              "          1.11189216e-01, -1.41320348e-01,  2.92207032e-01,\n",
              "          4.83208686e-01, -7.55891383e-01,  2.14137897e-01,\n",
              "         -3.26245666e-01,  4.99062598e-01, -3.93076390e-02,\n",
              "         -1.39388934e-01,  4.30381268e-01,  2.97039270e-01,\n",
              "          3.96237969e-01, -6.26668334e-05,  4.29916054e-01,\n",
              "         -4.99229312e-01,  4.72535431e-01, -4.22203481e-01,\n",
              "         -2.73271114e-01, -4.43190455e-01, -4.12467331e-01,\n",
              "         -2.18986601e-01, -2.20013067e-01, -4.80897546e-01,\n",
              "          7.68896639e-01,  2.53313303e-01,  1.35491952e-01,\n",
              "         -1.71695352e-01,  5.30262947e-01,  2.49025032e-01,\n",
              "          3.41111571e-01,  4.39904541e-01, -1.32057354e-01,\n",
              "          2.85328299e-01, -7.47692466e-01,  3.11548382e-01,\n",
              "         -2.10835055e-01,  2.58072793e-01, -6.34610537e-04,\n",
              "          9.12405178e-02,  6.34697556e-01,  2.12191865e-01,\n",
              "          1.77005395e-01, -7.72448242e-01,  1.30449206e-01,\n",
              "         -5.09945273e-01,  7.11797953e-01, -2.12086961e-02,\n",
              "         -1.38942927e-01,  7.82079875e-01,  5.62189557e-02,\n",
              "         -1.48358252e-02,  3.96412998e-01, -7.04084337e-01,\n",
              "          5.99550426e-01,  4.09473985e-01, -4.06854570e-01,\n",
              "         -3.04407835e-01, -6.10637307e-01, -6.77746773e-01,\n",
              "         -3.25844139e-02, -1.04047731e-01, -1.43598795e-01,\n",
              "          6.18327200e-01,  1.01271151e-02, -2.76709974e-01,\n",
              "         -1.12710334e-01,  6.06158316e-01,  1.91148907e-01,\n",
              "          5.72772861e-01,  5.04334979e-02, -4.36458498e-01,\n",
              "          6.48517728e-01, -2.68250972e-01, -2.71284729e-01,\n",
              "          2.05796793e-01, -6.71231627e-01,  1.89780191e-01,\n",
              "         -1.74414981e-02, -1.34945065e-01,  2.73597538e-02,\n",
              "         -8.35824087e-02, -7.59847313e-02,  1.62073985e-01,\n",
              "          1.01484746e-01,  3.35870713e-01, -1.41607570e-02,\n",
              "         -6.37826622e-01,  5.44041209e-03,  5.40290058e-01,\n",
              "         -1.82320066e-02,  7.31357783e-02, -2.07876056e-01,\n",
              "         -4.59313899e-01,  6.33389294e-01, -8.03954482e-01,\n",
              "         -5.60626611e-02, -3.41875255e-01, -6.06995486e-02,\n",
              "         -4.45035040e-01,  3.86701494e-01,  1.93603113e-01,\n",
              "         -6.86227739e-01, -3.49978358e-01, -6.57503664e-01]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),\n",
        "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]),\n",
        "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
        "}"
      ],
      "metadata": {
        "id": "e8lcUInRSBjM"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertBackbone(\n",
        "    vocabulary_size=30000,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    num_groups=1,\n",
        "    num_inner_repetitions=1,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=768,\n",
        "    intermediate_dim=3072,\n",
        "    max_sequence_length=12\n",
        ")"
      ],
      "metadata": {
        "id": "1Od1s8qqTCxh"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_data)"
      ],
      "metadata": {
        "id": "c8MQ0z9hTTap"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySJiyktmTV5O",
        "outputId": "980a93aa-5a48-4d21-81eb-e330d36a8abe"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence_output': <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              " array([[[-0.43679053, -0.2894092 ,  0.85675085, ...,  1.0371175 ,\n",
              "           1.3990874 , -0.68539274],\n",
              "         [-0.18379351, -0.45564273,  0.823195  , ...,  1.4603297 ,\n",
              "           1.31157   , -0.3632703 ],\n",
              "         [-0.1721516 , -0.36532483,  0.8304959 , ...,  0.8241616 ,\n",
              "           1.5280488 , -0.3765172 ],\n",
              "         ...,\n",
              "         [ 0.14934617, -0.09644508,  1.0238007 , ...,  1.5357054 ,\n",
              "           1.4012756 , -0.7498255 ],\n",
              "         [-0.20113334, -0.0215614 ,  1.1505114 , ...,  1.3296504 ,\n",
              "           0.85180557, -0.18828274],\n",
              "         [-0.39731118, -0.14718607,  0.96238077, ...,  1.6099639 ,\n",
              "           1.402038  , -0.19355036]]], dtype=float32)>,\n",
              " 'pooled_output': <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[ 3.80110219e-02,  3.31503212e-01,  1.19109906e-01,\n",
              "         -2.84547865e-01,  2.60098606e-01,  1.77821830e-01,\n",
              "         -2.10329324e-01, -2.00897291e-01, -5.24176061e-01,\n",
              "          5.72777018e-02, -1.55416504e-01,  5.49759448e-01,\n",
              "          1.82335392e-01,  1.21442042e-01,  6.74628973e-01,\n",
              "         -1.57735944e-01, -3.22533220e-01, -4.65209544e-01,\n",
              "         -4.00654167e-01,  1.46015182e-01, -9.56025496e-02,\n",
              "         -6.31428659e-02,  5.32180607e-01, -7.16360688e-01,\n",
              "          4.17287141e-01,  6.32801294e-01,  3.29962969e-01,\n",
              "         -2.85499424e-01, -3.40286642e-01, -3.26141953e-01,\n",
              "          3.61857563e-02,  7.00627327e-01,  8.11880678e-02,\n",
              "          4.24852446e-02, -1.41993493e-01, -1.49744248e-03,\n",
              "          5.06553352e-01,  5.39241731e-01, -1.85202897e-01,\n",
              "          3.39677393e-01, -1.83901072e-01,  1.46007657e-01,\n",
              "         -5.34698904e-01,  3.16241592e-01, -6.75678253e-01,\n",
              "          8.56916845e-01,  7.30523048e-03, -4.67630565e-01,\n",
              "         -2.08943605e-01, -4.90706354e-01, -5.77225387e-01,\n",
              "         -8.58707249e-01,  3.01483095e-01, -3.69826168e-01,\n",
              "          2.56669223e-02,  6.68382496e-02, -3.29477429e-01,\n",
              "         -2.57850528e-01, -3.68074030e-01,  4.90308315e-01,\n",
              "          2.64805973e-01, -7.12830424e-01, -7.54629970e-01,\n",
              "         -9.05026719e-02, -2.20385492e-01,  7.14293301e-01,\n",
              "          8.06982040e-01,  2.25432217e-01, -1.96039200e-01,\n",
              "         -1.99570745e-01, -1.20851602e-02, -3.06514114e-01,\n",
              "         -4.44794327e-01,  2.25771874e-01,  1.86948553e-01,\n",
              "          6.16744459e-01, -4.10023957e-01, -1.40466779e-01,\n",
              "          3.14983100e-01,  2.79610157e-01,  8.39055598e-01,\n",
              "         -4.25609767e-01,  1.13786541e-01,  6.19196177e-01,\n",
              "          2.89009750e-01,  2.13373184e-01, -1.69598147e-01,\n",
              "         -8.95180464e-01,  6.14146054e-01, -5.31417012e-01,\n",
              "          4.98447895e-01, -3.95615906e-01,  7.32500374e-01,\n",
              "         -3.38343024e-01, -7.00275898e-02, -4.58201170e-01,\n",
              "         -4.28095579e-01, -4.60537732e-01,  6.64481997e-01,\n",
              "          5.68284929e-01,  5.04083514e-01,  3.20155203e-01,\n",
              "         -4.90427643e-01,  4.28969692e-03, -6.82448983e-01,\n",
              "          3.87342125e-01,  2.05586642e-01, -3.37109834e-01,\n",
              "         -5.60202360e-01,  2.44549364e-02, -6.19044244e-01,\n",
              "         -1.79004952e-01, -1.89861029e-01, -2.93795735e-01,\n",
              "         -2.23973021e-03,  1.47480786e-01, -7.32529983e-02,\n",
              "          3.28331172e-01,  2.82322049e-01, -5.41184783e-01,\n",
              "         -2.30327565e-02, -4.58755702e-01, -1.99166447e-01,\n",
              "         -2.68515825e-01, -4.51272249e-01,  2.57549077e-01,\n",
              "          4.73671854e-01, -6.16372764e-01, -5.97996831e-01,\n",
              "         -5.69193304e-01, -2.74851084e-01, -1.69364754e-02,\n",
              "          7.54786551e-01, -4.61238593e-01,  7.22222030e-01,\n",
              "          2.85312265e-01, -2.18831480e-01, -3.68899971e-01,\n",
              "          7.72681415e-01, -2.41395626e-02, -2.77068287e-01,\n",
              "         -4.83123735e-02, -5.54241538e-01, -6.20264173e-01,\n",
              "         -1.47292137e-01,  2.80704796e-01, -1.61929175e-01,\n",
              "         -3.06233495e-01, -5.93069732e-01, -6.98041499e-01,\n",
              "          7.00389072e-02, -1.21706896e-01, -1.98805481e-01,\n",
              "         -8.49002153e-02,  2.45959759e-01,  4.62058820e-02,\n",
              "         -4.00691390e-01,  5.65052927e-02, -7.52069652e-02,\n",
              "         -7.21250415e-01, -5.85407138e-01,  1.77550584e-01,\n",
              "         -4.65776995e-02,  3.56518626e-01,  1.24603316e-01,\n",
              "         -1.67252332e-01, -1.34621203e-01, -1.34254858e-01,\n",
              "          3.33306909e-01,  3.07539374e-01, -3.08333454e-03,\n",
              "         -6.19563937e-01,  5.96628666e-01, -1.92484364e-01,\n",
              "         -1.05392538e-01,  5.31491220e-01,  3.56373638e-01,\n",
              "         -4.17735815e-01, -1.50861740e-01,  3.00076038e-01,\n",
              "          2.56376863e-01,  3.70435417e-02, -2.51339786e-02,\n",
              "          2.30048031e-01, -6.33562282e-02, -4.90606427e-01,\n",
              "         -2.56924957e-01,  8.96109521e-01, -3.55530530e-01,\n",
              "          5.81981838e-01, -1.58102870e-01, -1.15143307e-01,\n",
              "         -3.96155566e-01,  5.74136794e-01, -8.97977427e-02,\n",
              "         -2.11929217e-01,  2.59669237e-02, -6.25985026e-01,\n",
              "         -6.39464736e-01,  1.05245277e-01,  6.00302100e-01,\n",
              "         -4.25417513e-01,  3.36706102e-01,  3.55216444e-01,\n",
              "          6.59337163e-01, -3.43026556e-02,  3.81950468e-01,\n",
              "          1.99259922e-01,  5.12356460e-01, -5.73435277e-02,\n",
              "         -8.46326575e-02, -2.65657663e-01, -2.03363255e-01,\n",
              "          1.11442327e-01,  4.11656499e-01,  2.52070934e-01,\n",
              "          4.65982884e-01, -7.16909707e-01,  6.28936470e-01,\n",
              "         -3.82510573e-01, -6.16399527e-01, -1.55828938e-01,\n",
              "         -4.28942829e-01,  8.16864848e-01,  6.55175805e-01,\n",
              "          5.89099944e-01,  5.01059219e-02, -8.78713727e-01,\n",
              "          6.53251946e-01,  5.83043635e-01, -1.57245800e-01,\n",
              "         -8.74308884e-01, -5.68607748e-01,  5.53094685e-01,\n",
              "          5.02569616e-01, -1.70805484e-01,  6.47198081e-01,\n",
              "          5.38023353e-01, -3.74289513e-01, -2.22607031e-01,\n",
              "          2.01987028e-01,  8.92462060e-02,  8.00683498e-01,\n",
              "         -2.42960632e-01, -3.55201185e-01, -1.19461805e-01,\n",
              "          6.19405091e-01,  7.25954324e-02,  5.75996399e-01,\n",
              "         -9.32745859e-02, -4.19761002e-01, -8.69829357e-01,\n",
              "         -6.29078388e-01,  2.68239707e-01, -4.62944537e-01,\n",
              "         -3.79375905e-01, -3.27467203e-01,  9.57496837e-03,\n",
              "          1.89602301e-01,  1.24862313e-01,  5.69663458e-02,\n",
              "          1.25904130e-02,  4.84179646e-01, -6.77631915e-01,\n",
              "         -6.56288087e-01,  5.46315312e-01,  1.73342600e-01,\n",
              "          6.10898495e-01,  2.47416109e-01,  4.33624268e-01,\n",
              "         -4.71503019e-01, -9.62797925e-02,  7.64727354e-01,\n",
              "         -6.49293780e-01,  1.35761604e-01,  6.50293410e-01,\n",
              "          8.40162098e-01,  2.98834473e-01, -1.99194163e-01,\n",
              "          4.48592186e-01, -3.12077969e-01, -5.03583372e-01,\n",
              "         -4.62245435e-01,  4.71966445e-01,  2.61136085e-01,\n",
              "          4.10813600e-01,  3.59421104e-01, -2.60267943e-01,\n",
              "         -1.90877784e-02,  7.26457983e-02, -2.22788587e-01,\n",
              "          4.39695179e-01, -4.57100749e-01,  4.99741256e-01,\n",
              "          1.75039560e-01,  6.72691464e-01, -3.71520102e-01,\n",
              "          6.34988666e-01, -2.40925532e-02,  7.55360305e-01,\n",
              "          3.55610371e-01, -3.68880063e-01,  2.61114031e-01,\n",
              "          3.99025470e-01, -5.61856091e-01,  7.65229583e-01,\n",
              "         -2.81682879e-01,  1.89718664e-01,  3.42655182e-01,\n",
              "         -5.11559844e-01, -2.22133562e-01,  2.09104121e-02,\n",
              "          9.88043249e-02, -6.80899918e-01,  5.85835457e-01,\n",
              "          7.81092405e-01, -1.50798202e-01, -3.07950646e-01,\n",
              "          1.10094167e-01,  4.10027839e-02, -3.62223476e-01,\n",
              "         -1.30137354e-01, -6.76891625e-01, -7.03702793e-02,\n",
              "          4.43518966e-01,  6.90557837e-01,  2.04867661e-01,\n",
              "          1.97564363e-01, -2.32357368e-01,  4.77949947e-01,\n",
              "          5.67267239e-01,  2.57162333e-01,  4.17025298e-01,\n",
              "         -1.44341826e-01,  7.15863466e-01,  8.41676652e-01,\n",
              "         -4.38102812e-01, -7.79252648e-01, -1.21909216e-01,\n",
              "          6.06465995e-01,  1.76840290e-01, -2.70209759e-01,\n",
              "          6.43618166e-01,  9.60679650e-02, -7.07502186e-01,\n",
              "          3.76837909e-01, -3.68409529e-02,  5.78797936e-01,\n",
              "          2.23303884e-01,  5.53080738e-01,  3.80060196e-01,\n",
              "         -4.47118253e-01, -7.20668137e-02, -6.44605160e-01,\n",
              "         -1.51887208e-01, -1.60253465e-01, -2.55148828e-01,\n",
              "          1.95688456e-01,  5.63041389e-01, -4.02349353e-01,\n",
              "          6.43891931e-01, -2.77494013e-01,  3.52788687e-01,\n",
              "          1.72317103e-01, -6.30065739e-01,  2.76109040e-01,\n",
              "          4.31048661e-01, -3.25346172e-01, -4.99635726e-01,\n",
              "          3.70463669e-01, -2.43265852e-02, -1.96463540e-01,\n",
              "         -3.31601948e-01, -6.81583643e-01,  3.73382747e-01,\n",
              "          3.24707657e-01, -1.69339269e-01, -5.18407285e-01,\n",
              "         -7.27674514e-02,  5.28675318e-01, -3.33730608e-01,\n",
              "         -8.50755125e-02, -6.45155549e-01, -4.15446788e-01,\n",
              "         -9.27905962e-02,  6.21669173e-01,  6.26372516e-01,\n",
              "         -4.25838381e-01,  6.86980605e-01,  1.93131611e-01,\n",
              "         -4.54440534e-01, -1.83971331e-01, -6.49738550e-01,\n",
              "         -4.81687039e-01,  1.02991469e-01, -1.46553949e-01,\n",
              "         -1.92877855e-02, -3.90122950e-01,  5.15121102e-01,\n",
              "          1.38917401e-01,  3.48872870e-01,  2.88531363e-01,\n",
              "         -5.95631003e-01, -4.21678811e-01,  1.71001896e-01,\n",
              "          1.22923311e-02, -5.99307120e-01,  5.71237445e-01,\n",
              "          5.13779461e-01,  2.40880519e-01, -2.25624725e-01,\n",
              "         -3.55580211e-01, -1.59788355e-01,  1.50739938e-01,\n",
              "          8.31679344e-01,  1.58029824e-01, -5.30704081e-01,\n",
              "          4.35016185e-01, -1.40740290e-01,  6.81078792e-01,\n",
              "         -3.52732986e-01,  5.57401478e-01, -4.31716472e-01,\n",
              "          3.23875785e-01,  1.62340552e-01, -5.55159688e-01,\n",
              "          2.17518955e-01,  8.62430632e-02,  2.43786633e-01,\n",
              "          3.71919721e-02,  1.84731126e-01,  1.61296651e-01,\n",
              "         -9.61695611e-02, -2.29359716e-01,  8.03842843e-02,\n",
              "          4.10927944e-02,  1.23231756e-02,  1.72396511e-01,\n",
              "         -2.87067771e-01,  2.48443149e-02,  4.10930842e-01,\n",
              "          1.14836492e-01,  4.68502156e-02,  1.17765561e-01,\n",
              "         -1.88957408e-01,  3.77097070e-01,  3.49760801e-01,\n",
              "          4.62691903e-01, -1.86491668e-01, -4.82624263e-01,\n",
              "          9.63772982e-02, -3.03342491e-01, -4.59971018e-02,\n",
              "         -2.92173624e-01, -4.96612370e-01, -3.90437424e-01,\n",
              "          6.36975288e-01, -2.56088078e-01, -3.90098363e-01,\n",
              "         -3.83072287e-01,  5.81736684e-01, -2.74653882e-01,\n",
              "          6.17773116e-01, -4.11926657e-01,  3.25337768e-01,\n",
              "          1.41619354e-01,  9.37270746e-02, -4.17050123e-02,\n",
              "          4.15493637e-01, -3.08209807e-01,  1.46057278e-01,\n",
              "         -5.89555562e-01, -4.99474823e-01,  6.61715269e-02,\n",
              "         -7.42411852e-01, -6.04304612e-01,  5.36284387e-01,\n",
              "          3.42399329e-02,  4.62297834e-02, -1.57637089e-01,\n",
              "          4.27449763e-01, -2.12959014e-02, -7.47389197e-02,\n",
              "          1.84032381e-01, -2.39346102e-02,  2.08152056e-01,\n",
              "          2.85880506e-01, -4.48797017e-01, -1.93529382e-01,\n",
              "         -2.60800928e-01,  2.75474846e-01,  8.04414451e-01,\n",
              "          6.06894851e-01,  8.99636969e-02, -6.30615711e-01,\n",
              "          2.53774136e-01,  1.54367551e-01,  2.12740779e-01,\n",
              "          5.04812777e-01, -3.93407196e-01,  4.17653173e-01,\n",
              "          7.79425502e-01,  1.14270605e-01,  2.96238005e-01,\n",
              "          3.41304779e-01, -1.08673140e-01, -5.14120340e-01,\n",
              "          4.66598660e-01,  7.72375381e-04,  2.54706711e-01,\n",
              "         -5.49838960e-01, -1.18581697e-01,  7.17441380e-01,\n",
              "         -2.58813083e-01, -4.80923755e-03,  4.44848627e-01,\n",
              "          2.68425256e-01, -3.73605937e-01, -4.03759778e-01,\n",
              "          2.84337461e-01, -4.17571247e-01, -2.94033229e-01,\n",
              "         -3.58390838e-01, -3.21250051e-01, -6.04951531e-02,\n",
              "          7.21404850e-02,  1.80132121e-01, -6.20381653e-01,\n",
              "         -3.63689274e-01, -2.23404393e-01, -6.14226043e-01,\n",
              "         -1.26404181e-01,  5.64401709e-02, -9.41543579e-02,\n",
              "         -1.98295563e-01,  1.83128938e-01,  1.71049207e-01,\n",
              "         -1.29874304e-01,  2.16502517e-01, -4.62675780e-01,\n",
              "         -2.00606465e-01,  3.78821254e-01,  4.90964770e-01,\n",
              "         -4.99968261e-01, -6.50446236e-01, -4.62034456e-02,\n",
              "         -6.04130507e-01, -7.64228553e-02,  5.91656148e-01,\n",
              "          5.74806750e-01,  6.55788928e-02, -1.41662508e-01,\n",
              "          2.46121347e-01,  1.54628173e-01, -3.63940001e-01,\n",
              "          2.40611844e-02,  4.97637033e-01, -4.22407806e-01,\n",
              "         -4.29773144e-02,  3.02047431e-01, -4.85966623e-01,\n",
              "          7.74834335e-01, -1.49394572e-01,  1.22431986e-01,\n",
              "          5.83100140e-01,  1.88438430e-01, -3.14599127e-01,\n",
              "          4.63218808e-01,  2.55356014e-01, -1.82614341e-01,\n",
              "          4.68203008e-01,  1.16649732e-01, -1.60492539e-01,\n",
              "         -1.37298286e-01, -1.86736479e-01, -4.43365514e-01,\n",
              "          3.52674842e-01, -7.75228888e-02, -3.76590818e-01,\n",
              "          2.82770306e-01,  3.17355156e-01, -2.11432993e-01,\n",
              "          6.01055264e-01, -5.34152210e-01,  2.99978048e-01,\n",
              "         -4.97628987e-01,  2.83932388e-02, -5.31144321e-01,\n",
              "          1.47570834e-01, -2.79752940e-01, -4.59920354e-02,\n",
              "         -5.69895506e-01,  3.19492877e-01,  3.63896608e-01,\n",
              "         -5.88467240e-01,  8.90016109e-02, -4.02283192e-01,\n",
              "          6.15878776e-03,  5.75653970e-01, -3.85713503e-02,\n",
              "          4.12318617e-01, -3.69254351e-02,  2.07259938e-01,\n",
              "         -5.20607308e-02, -9.70646366e-02,  5.48629165e-01,\n",
              "         -5.67847311e-01,  2.60719121e-01, -4.64879006e-01,\n",
              "          6.53042138e-01, -1.29209220e-01,  2.19262734e-01,\n",
              "         -5.54596841e-01,  6.78054929e-01,  4.05795217e-01,\n",
              "         -1.25089332e-01, -6.97289109e-01, -8.75026524e-01,\n",
              "          8.00596297e-01, -3.21199566e-01, -4.37842548e-01,\n",
              "          6.15578115e-01, -3.58501911e-01, -5.27022064e-01,\n",
              "          4.00587261e-01, -2.25587655e-02, -6.17634058e-01,\n",
              "         -9.48222727e-02, -4.72707570e-01, -5.30763924e-01,\n",
              "         -1.49583131e-01, -6.21996284e-01, -6.78253293e-01,\n",
              "          4.46268499e-01, -8.01685378e-02, -1.78370357e-01,\n",
              "          1.60441384e-01,  2.76589133e-02,  2.72891283e-01,\n",
              "         -5.63164234e-01, -5.49574256e-01, -3.88226323e-02,\n",
              "         -4.02580164e-02, -3.35998595e-01,  6.66327894e-01,\n",
              "         -3.97442251e-01, -4.77156788e-01, -1.22190647e-01,\n",
              "          8.86287093e-02, -3.87541145e-01,  1.21908262e-01,\n",
              "          2.97704339e-01,  4.83686328e-01,  4.01743948e-01,\n",
              "          5.28414190e-01,  2.29573295e-01,  4.29343283e-02,\n",
              "          4.26663965e-01, -6.25196338e-01, -1.47604838e-01,\n",
              "          2.55598217e-01,  6.32949412e-01,  6.86293542e-01,\n",
              "         -2.38262221e-01,  2.31680319e-01, -5.21942794e-01,\n",
              "         -2.03831881e-01, -4.76326168e-01,  2.03996420e-01,\n",
              "          2.76510864e-01, -3.64136487e-01,  5.43052971e-01,\n",
              "          3.90365034e-01, -5.99338055e-01, -3.87302011e-01,\n",
              "         -2.10935533e-01,  5.90572134e-02,  4.79411662e-01,\n",
              "         -4.50975627e-01,  3.40785861e-01,  3.73395830e-01,\n",
              "         -2.80464321e-01, -3.80222976e-01, -8.70960355e-01,\n",
              "         -4.28654552e-01, -6.98497057e-01,  3.38590831e-01,\n",
              "          3.83861482e-01, -4.83873844e-01,  2.88862050e-01,\n",
              "          2.78806120e-01, -5.00018358e-01, -2.07784563e-01,\n",
              "          5.66439986e-01, -5.92795014e-01,  8.44660997e-02,\n",
              "          6.78075776e-02,  7.19318628e-01,  4.79062237e-02,\n",
              "         -3.72014493e-01,  1.15348790e-02, -2.25604072e-01,\n",
              "         -7.09582567e-01, -1.64929062e-01,  4.36905682e-01,\n",
              "          5.32025874e-01,  3.80960971e-01,  4.47230160e-01,\n",
              "         -6.64189279e-01,  5.06064296e-01,  8.84019658e-02,\n",
              "         -4.34178472e-01,  3.68114173e-01,  1.73352808e-01,\n",
              "          5.61056614e-01,  4.21716243e-01,  1.47050157e-01,\n",
              "          7.61115193e-01, -6.90930367e-01, -3.70267719e-01,\n",
              "          1.12299807e-01,  3.31181884e-01,  5.00817895e-01,\n",
              "         -3.43847930e-01,  4.31047410e-01,  7.13486597e-02,\n",
              "          2.69873410e-01,  5.16894996e-01,  2.70924956e-01,\n",
              "          1.14474609e-01, -1.99430719e-01, -6.07818007e-01,\n",
              "         -1.34151012e-01, -4.20066983e-01,  1.25282660e-01,\n",
              "         -1.10128842e-01, -5.83588958e-01,  1.08504876e-01,\n",
              "         -3.37378174e-01,  2.72093356e-01, -5.51792324e-01,\n",
              "         -6.73226774e-01,  3.72956336e-01, -6.83908224e-01,\n",
              "         -1.03352100e-01, -1.01058073e-01,  1.80558383e-01,\n",
              "          1.66024774e-01,  2.43561685e-01,  3.31282437e-01,\n",
              "         -2.71614701e-01, -7.28824079e-01,  1.51514664e-01,\n",
              "          1.28445551e-02, -3.81638527e-01,  2.66254455e-01,\n",
              "         -3.31837207e-01, -3.29319090e-01, -5.86827286e-02,\n",
              "          4.34453517e-01, -1.08352512e-01,  4.34079289e-01,\n",
              "         -4.24624413e-01, -5.05620062e-01, -2.51749486e-01,\n",
              "         -1.99493423e-01, -7.08567560e-01,  1.56754136e-01]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vMWKPLgnTWve"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}