{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0rOJSwUaOrV",
        "outputId": "df0b395f-4939-44a0-983c-eeabe70d183a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (23.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.6.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (13.7.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.5)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (4.66.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (0.0.7)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (3.9.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.15.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2023.11.17)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.5.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text->keras_nlp) (3.2.2)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.10/dist-packages (4.9.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.1.8)\n",
            "Requirement already satisfied: etils[enp,epath,etree]>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.6.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.23.5)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.3)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (3.20.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (5.9.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.31.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (2.4.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.10.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (4.66.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (1.14.1)\n",
            "Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_datasets) (0.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (2023.6.0)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (6.1.1)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (4.5.0)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]>=0.9.0->tensorflow_datasets) (3.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->tensorflow_datasets) (2023.11.17)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from promise->tensorflow_datasets) (1.16.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata->tensorflow_datasets) (1.62.0)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.15.0)\n",
            "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.16,>=2.15.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tensorflow-text) (3.2.2)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (2.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_nlp\n",
        "!pip install tensorflow\n",
        "!pip install tensorflow_datasets\n",
        "!pip install tensorflow-text\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import keras_nlp\n",
        "import tensorflow_datasets\n",
        "import keras\n",
        "from keras_nlp.models import AlbertTokenizer, AlbertPreprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAJUyqWgaXmo",
        "outputId": "8c89b6b3-c2c5-40fc-f913-13a30c2de94c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using TensorFlow backend\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer.from_preset(\"albert_base_en_uncased\",)"
      ],
      "metadata": {
        "id": "buH7ZYIbalZ8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.tokenize([\"Goat is good\", \"Sheep is good\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aUHHP23gaydB",
        "outputId": "5895c2da-c8ec-4c71-8fff-a65c7111df8d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[13, 1, 111, 721, 25, 254],\n",
              " [13, 1, 438, 3492, 25, 254]]>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "s2oAYQoRJ6tA"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bytes_io = io.BytesIO()"
      ],
      "metadata": {
        "id": "FyWTrq4JJxD4"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qJXkTosZJzcj",
        "outputId": "2d2995d4-0999-4775-f262-fb274435a248"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.35.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.60.0)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "h0QLddZFJ3Gh"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([\"The goat was huge\"])"
      ],
      "metadata": {
        "id": "e8iwwi-vJ7yT"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-2yxmBaYKGul",
        "outputId": "bd375819-352e-47e4-f0d7-4cf06bd7b4aa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm"
      ],
      "metadata": {
        "id": "vNumqghFKirN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator=ds.as_numpy_iterator(),\n",
        "    model_writer = bytes_io,\n",
        "    vocab_size=9,\n",
        "    model_type=\"WORD\",\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    pad_piece=\"<pad>\",\n",
        "    unk_piece=\"<unk>\",\n",
        "    bos_piece=\"[CLS]\",\n",
        "    eos_piece=\"[SEP]\",\n",
        "    user_defined_symbols=\"[MASK]\",\n",
        ")"
      ],
      "metadata": {
        "id": "cbR2U5rEKm34"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer(proto=bytes_io.getvalue())"
      ],
      "metadata": {
        "id": "a3xo3hl1LNUM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer(\"The goat is a masterpiece\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VeDDwG0BLTe5",
        "outputId": "1ae0a10e-06e1-4d18-88f8-af0e8fc30b91"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=int32, numpy=array([5, 6, 1], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor.from_preset(\"albert_base_en_uncased\")"
      ],
      "metadata": {
        "id": "0IwYYP3zHLom"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"What a game!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3sBa3p4CHR7f",
        "outputId": "cf91b35c-d95e-47e5-ce2f-c95c4c92a844"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([   2,   13,    1, 6775,   21,  250,  187,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The quick fox jumped\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KqNQ_ouHvqS",
        "outputId": "eeaa58ff-6a7d-4968-d532-35dd86353f29"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([   2,   13,    1,  438, 2231, 2385, 4298,    3,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor([\"Is the goat good?\", \"Is the cow big?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-3J3K_fH1zL",
        "outputId": "bf87914c-644f-4b51-9c14-310a612c8fdb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
              " array([[ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0]], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(2, 512), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(2, 512), dtype=bool, numpy=\n",
              " array([[ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor([\"What a cow?\", \"Is that a rabbit?\", \"Is this a tiger?\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "In_3SYy7I3Bq",
        "outputId": "d7ac7837-951f-42b8-e10a-f5462072e79b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
              " array([[ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0],\n",
              "        [ 2, 13,  1, ...,  0,  0,  0]], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(3, 512), dtype=int32, numpy=\n",
              " array([[0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0],\n",
              "        [0, 0, 0, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(3, 512), dtype=bool, numpy=\n",
              " array([[ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False],\n",
              "        [ True,  True,  True, ..., False, False, False]])>}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor(tokenizer)"
      ],
      "metadata": {
        "id": "2vCVLvY_JCug"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The goat is a masterpiece\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6HvjdZRfJIiK",
        "outputId": "80c8e3e3-b080-46be-9ee8-5e1149455639"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([2, 5, 6, 1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bytes_io = io.BytesIO()"
      ],
      "metadata": {
        "id": "1EG7wcImJOEg"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = tf.data.Dataset.from_tensor_slices([\"The story is interesting\"])"
      ],
      "metadata": {
        "id": "47L4itc0JeWv"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spm.SentencePieceTrainer.train(\n",
        "    sentence_iterator = ds.as_numpy_iterator(),\n",
        "    model_writer= bytes_io,\n",
        "    vocab_size=9,\n",
        "    model_type=\"WORD\",\n",
        "    pad_id=0,\n",
        "    unk_id=1,\n",
        "    bos_id=2,\n",
        "    eos_id=3,\n",
        "    pad_piece=\"<pad>\",\n",
        "    unk_piece=\"<unk>\",\n",
        "    bos_piece=\"[CLS]\",\n",
        "    eos_piece=\"[SEP]\",\n",
        "    user_defined_symbols=\"[MASK]\"\n",
        ")"
      ],
      "metadata": {
        "id": "nGhsg4xfJkRm"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AlbertTokenizer(proto=bytes_io.getvalue(),)"
      ],
      "metadata": {
        "id": "kGVhJqmbJ_iV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = AlbertPreprocessor(tokenizer)"
      ],
      "metadata": {
        "id": "1EM-Yk__KIxS"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor(\"The story is interesting\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3J0_E4TKL2L",
        "outputId": "0685bef5-6169-4219-81ab-acc196844d6c"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'token_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([2, 5, 8, 7, 6, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'segment_ids': <tf.Tensor: shape=(512,), dtype=int32, numpy=\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0], dtype=int32)>,\n",
              " 'padding_mask': <tf.Tensor: shape=(512,), dtype=bool, numpy=\n",
              " array([ True,  True,  True,  True,  True,  True, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False])>}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "first = tf.constant([\"The story is interesting\", \"the story is a mystery\"])"
      ],
      "metadata": {
        "id": "404J3YfVKOoh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "second = tf.constant([\"The story looks interesting and cool\", \"Is that a phone?\"])"
      ],
      "metadata": {
        "id": "7M_rkFuDLcax"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tf.constant([1, 1])"
      ],
      "metadata": {
        "id": "6DcfLdrzLjXG"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Map labeled single sentence\n",
        "ds = tf.data.Dataset.from_tensor_slices((first, label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ObjjIioyLlNN"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices(first)\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "IBGuwfi3Lo5S"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices(((first, second), label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "7v7FMR1CL83l"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices((first, second))"
      ],
      "metadata": {
        "id": "1z7P0tIJMM8N"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(lambda first, second: preprocessor(x=(first, second)), num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "KvDvx421MWmI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOP4EjaOMfeG",
        "outputId": "365e7b17-3de7-4756-c30f-38d9755b68e4"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec={'token_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'segment_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(512,), dtype=tf.bool, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "third = tf.constant([\"The game was well played\", \"The game was interesting, isn't it?\"])\n",
        "fourth = tf.constant([\"The fox is quick\", \"The tiger is too quick\"])"
      ],
      "metadata": {
        "id": "hapQ7WaRMhTw"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label = tf.constant([1, 1])"
      ],
      "metadata": {
        "id": "f_S6dZuIPYWU"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices((third, fourth))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "RoYsAH0RPa17"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled single sentences\n",
        "ds = tf.data.Dataset.from_tensor_slices(third)\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "UPYEgTOvPnpb"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map labeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices(((third, fourth), label))\n",
        "ds = ds.map(preprocessor, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "IPBRYAStPz8b"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#map unlabeled sentence pairs\n",
        "ds = tf.data.Dataset.from_tensor_slices((third, fourth))"
      ],
      "metadata": {
        "id": "OPDvvJxpQDUk"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(\n",
        "    lambda third, fourth:preprocessor(x=(third, fourth)),\n",
        "    num_parallel_calls=tf.data.AUTOTUNE\n",
        ")"
      ],
      "metadata": {
        "id": "gAyzhwNdQVcO"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpaR3RwXQdfB",
        "outputId": "8e4e5f1a-05fb-42d0-865e-048c2b6ec7e3"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec={'token_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'segment_ids': TensorSpec(shape=(512,), dtype=tf.int32, name=None), 'padding_mask': TensorSpec(shape=(512,), dtype=tf.bool, name=None)}>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_nlp.models import AlbertBackbone"
      ],
      "metadata": {
        "id": "kcczL7RCQ7BA"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "QGG92MXPReC5"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),\n",
        "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]),\n",
        "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
        "}"
      ],
      "metadata": {
        "id": "zjltZrRBRpob"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertBackbone(\n",
        "    vocabulary_size=30000,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    num_groups=1,\n",
        "    num_inner_repetitions=1,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=768,\n",
        "    intermediate_dim=3072,\n",
        "    max_sequence_length=12,\n",
        ")"
      ],
      "metadata": {
        "id": "RexVuW0MR7kT"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_data)"
      ],
      "metadata": {
        "id": "fu4LsEQDR-h5"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0uwB-B_5SAWI",
        "outputId": "abb9c2f2-218d-4684-d1a1-7486bf6feea7"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence_output': <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              " array([[[-0.7213105 , -1.6086907 ,  1.0146646 , ..., -0.47958714,\n",
              "           0.30777895,  0.13305013],\n",
              "         [-0.3592714 , -2.004273  ,  1.2183511 , ..., -0.76225096,\n",
              "           0.51566917,  0.5766828 ],\n",
              "         [-0.5072842 , -2.2241697 ,  1.2947727 , ..., -1.2558162 ,\n",
              "           0.5181343 ,  0.10891744],\n",
              "         ...,\n",
              "         [-0.68403184, -1.765363  ,  0.61937   , ..., -1.0953411 ,\n",
              "           0.6547122 , -0.40986043],\n",
              "         [-0.77370816, -1.7514365 ,  0.6784403 , ..., -1.059352  ,\n",
              "          -0.02456058, -0.10135846],\n",
              "         [-0.7822539 , -1.5234926 ,  0.81674945, ..., -1.1122056 ,\n",
              "           0.72969407,  0.0115099 ]]], dtype=float32)>,\n",
              " 'pooled_output': <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[-3.72024238e-01,  2.17629150e-01,  3.11642468e-01,\n",
              "          3.99030447e-01,  3.09600204e-01,  4.59668696e-01,\n",
              "         -4.66012865e-01,  6.26449510e-02,  2.07674220e-01,\n",
              "         -1.84977427e-01, -3.99602085e-01,  3.91077101e-01,\n",
              "          7.14008331e-01,  3.25505078e-01,  1.76015384e-02,\n",
              "         -2.19297335e-01,  5.80331981e-01,  3.84894758e-01,\n",
              "         -8.50447416e-01,  5.93363702e-01, -3.18763226e-01,\n",
              "          4.68780249e-01,  5.36091506e-01,  4.95100319e-01,\n",
              "          3.61861140e-01, -2.58340806e-01, -5.18214881e-01,\n",
              "          2.34424040e-01,  2.27139950e-01,  1.96973816e-01,\n",
              "         -6.42843962e-01, -2.83243656e-01,  3.42790902e-01,\n",
              "         -9.11658183e-02, -2.94789076e-01, -1.50742799e-01,\n",
              "         -3.83253604e-01,  5.10959983e-01,  6.90841138e-01,\n",
              "          3.57363343e-01,  6.54079795e-01,  2.91094463e-02,\n",
              "          8.36590707e-01, -9.06080231e-02,  6.61465153e-03,\n",
              "          5.85565567e-01, -6.74069598e-02,  1.73972890e-01,\n",
              "          3.67815942e-01, -2.65583783e-01,  5.34355223e-01,\n",
              "         -1.67214662e-01,  2.81301439e-01,  4.05569732e-01,\n",
              "         -8.69785786e-01, -5.52860916e-01, -1.49100110e-01,\n",
              "          4.17635649e-01,  1.92134291e-01, -1.21338278e-01,\n",
              "         -1.26199499e-01, -3.06200534e-01,  7.07366243e-02,\n",
              "          2.45732337e-01, -4.12542224e-01, -4.29725111e-01,\n",
              "         -6.01886988e-01,  1.54093325e-01,  5.61966240e-01,\n",
              "          4.46840338e-02, -1.69069469e-01, -5.46957672e-01,\n",
              "         -2.16176927e-01, -1.20318338e-01,  5.37841678e-01,\n",
              "          4.89072442e-01, -1.32024258e-01,  2.00498149e-01,\n",
              "          5.27642012e-01,  3.43227834e-02,  4.71560031e-01,\n",
              "         -1.87147245e-01, -3.93158309e-02,  5.62404931e-01,\n",
              "         -4.78756458e-01, -9.43617001e-02,  1.94023550e-01,\n",
              "          5.21706700e-01,  5.02621293e-01, -3.80450010e-01,\n",
              "          1.68973103e-01,  4.83876139e-01, -3.50986540e-01,\n",
              "          2.51956195e-01,  7.56461993e-02,  2.27868721e-01,\n",
              "          5.81655502e-01,  3.86322349e-01,  3.05995226e-01,\n",
              "         -1.71729907e-01,  3.94047052e-01,  5.68296492e-01,\n",
              "         -6.50593877e-01,  5.62248349e-01, -3.92427057e-01,\n",
              "         -2.84201503e-02,  4.83540744e-01, -3.74761820e-01,\n",
              "         -2.08001390e-01,  1.73438549e-01,  5.39095521e-01,\n",
              "          3.80338915e-02,  2.85077095e-01, -2.19457775e-01,\n",
              "          1.21691324e-01,  2.14316294e-01, -3.05869550e-01,\n",
              "          7.19301403e-01, -2.11457357e-01,  2.38855067e-03,\n",
              "          7.72623241e-01, -7.11607337e-01, -1.41971007e-01,\n",
              "         -5.62372983e-01, -2.36842930e-02,  1.20144852e-01,\n",
              "          2.30033726e-01, -5.09095728e-01, -4.20682281e-02,\n",
              "          5.02482057e-01,  6.27112761e-02, -2.15979576e-01,\n",
              "         -6.63374782e-01, -6.55772448e-01, -6.06513806e-02,\n",
              "         -7.05723763e-01, -4.56266224e-01,  3.33987065e-02,\n",
              "          3.48427355e-01,  3.59812886e-01,  5.98258436e-01,\n",
              "          2.14402184e-01,  1.56927273e-01,  3.78583848e-01,\n",
              "          4.36908782e-01,  7.69189298e-01, -2.46743605e-01,\n",
              "         -8.51223767e-01, -7.24515468e-02,  5.81468008e-02,\n",
              "          6.73385561e-01,  5.44035316e-01, -4.59404737e-01,\n",
              "         -2.34277942e-03,  5.70855916e-01,  2.37857118e-01,\n",
              "         -1.25767589e-01, -8.31277866e-04, -1.80945247e-01,\n",
              "         -1.41212359e-01,  7.36179203e-02, -7.25347757e-01,\n",
              "          7.26864338e-01, -2.95453817e-01,  6.22565687e-01,\n",
              "         -2.73153096e-01, -7.70136118e-02,  6.24242663e-01,\n",
              "         -1.24313040e-02, -9.05759633e-01, -4.96776253e-02,\n",
              "          2.63010971e-02,  5.65555632e-01,  5.10533750e-01,\n",
              "         -1.98165447e-01, -6.23444438e-01, -5.86738288e-01,\n",
              "          4.48680520e-01, -4.78288651e-01, -9.48761329e-02,\n",
              "         -3.20809901e-01, -5.01550376e-01,  1.76185772e-01,\n",
              "          2.52834737e-01,  3.36301535e-01, -5.12234151e-01,\n",
              "          6.05162501e-01, -2.78916776e-01,  6.88112259e-01,\n",
              "         -3.76861900e-01,  6.12175941e-01, -2.89848566e-01,\n",
              "         -4.12250429e-01,  5.14835060e-01,  4.33275193e-01,\n",
              "         -1.71170875e-01,  5.29136360e-01,  2.49392763e-01,\n",
              "         -8.08406413e-01,  6.99654877e-01,  3.73286963e-01,\n",
              "         -3.50478888e-01,  1.27359986e-01,  5.80528200e-01,\n",
              "          1.09032914e-02, -1.67435348e-01,  6.03530645e-01,\n",
              "          3.17417115e-01, -5.51819682e-01, -1.15373954e-01,\n",
              "          5.13922632e-01, -5.37720501e-01, -4.64540035e-01,\n",
              "         -1.49260655e-01,  4.66986060e-01,  1.76496893e-01,\n",
              "          7.91612208e-01, -3.09318930e-01,  1.82842150e-01,\n",
              "         -2.13615909e-01, -1.56458065e-01,  1.24728836e-01,\n",
              "         -7.00969398e-01,  2.39261985e-01, -5.43156751e-02,\n",
              "          9.35715139e-02,  1.03051789e-01,  2.19056353e-01,\n",
              "         -1.82594389e-01,  4.37613547e-01, -9.24693719e-02,\n",
              "          6.45805776e-01, -5.84277451e-01,  4.51173633e-01,\n",
              "          6.70127511e-01, -2.46841367e-02, -4.14936513e-01,\n",
              "         -7.77058959e-01,  1.25250146e-01,  1.03498958e-01,\n",
              "         -6.05768040e-02,  1.34957001e-01, -3.84492546e-01,\n",
              "          2.31765121e-01, -4.12461221e-01,  8.36667597e-01,\n",
              "         -5.46938479e-01,  7.34366119e-01,  4.09053266e-01,\n",
              "         -3.97256464e-01, -4.75311905e-01,  5.36588788e-01,\n",
              "         -3.05870563e-01,  6.99997246e-01,  7.31733084e-01,\n",
              "         -4.28501129e-01, -6.03896320e-01,  3.00466537e-01,\n",
              "          1.84926927e-01, -4.20368671e-01,  1.42532408e-01,\n",
              "          1.02095120e-01, -3.69503140e-01, -3.79713804e-01,\n",
              "         -2.23042712e-01, -8.34076256e-02,  7.00346231e-01,\n",
              "          4.40533906e-01, -1.49958834e-01, -1.97301865e-01,\n",
              "          2.42415875e-01,  3.28613758e-01, -3.79163325e-01,\n",
              "          2.90576536e-02, -5.63020781e-02,  9.25268829e-02,\n",
              "         -2.35102981e-01, -8.75421226e-01, -7.95520902e-01,\n",
              "          4.81371209e-02, -1.87000215e-01,  5.17027915e-01,\n",
              "         -2.18620434e-01,  7.35546425e-02, -9.69987828e-03,\n",
              "         -7.18873069e-02,  6.78918600e-01,  2.29225546e-01,\n",
              "         -8.10046941e-02,  3.76423061e-01, -3.61447036e-01,\n",
              "          5.43703198e-01,  5.93690947e-03,  1.82283178e-01,\n",
              "         -1.95186734e-01, -3.24631572e-01, -3.06197792e-01,\n",
              "          5.77604413e-01, -6.82169557e-01,  8.17575380e-02,\n",
              "          3.01535785e-01, -5.38619399e-01,  2.91796952e-01,\n",
              "         -3.54221135e-01, -1.60022840e-01,  4.01097208e-01,\n",
              "         -1.37086526e-01,  4.88529027e-01, -6.13785267e-01,\n",
              "         -3.99991959e-01,  3.22424471e-01, -5.95352232e-01,\n",
              "         -7.86529839e-01, -5.11601493e-02, -5.62939167e-01,\n",
              "          4.30507362e-01, -3.49814981e-01,  7.79787123e-01,\n",
              "          4.19063300e-01, -7.75710762e-01,  7.71585524e-01,\n",
              "         -4.11095321e-01,  8.55585858e-02,  4.68755484e-01,\n",
              "         -1.32128939e-01,  2.28229687e-01,  3.35100591e-01,\n",
              "          1.32832348e-01, -3.51495564e-01, -2.41306379e-01,\n",
              "          1.64701194e-01, -6.96254790e-01, -2.35479385e-01,\n",
              "         -2.45056078e-01, -6.31334782e-01,  2.79500842e-01,\n",
              "          4.58352000e-01, -2.47019872e-01, -1.18802860e-01,\n",
              "          4.21449006e-01,  4.03530523e-03,  7.06129372e-01,\n",
              "          2.82307327e-01, -9.39175079e-04,  7.79014081e-02,\n",
              "         -6.34670675e-01,  5.68349101e-02, -6.44551694e-01,\n",
              "         -1.34864852e-01,  1.94116101e-01, -3.82254243e-01,\n",
              "          2.55651861e-01,  7.94844236e-03,  6.63876474e-01,\n",
              "          4.32566822e-01,  2.47682244e-01,  2.89700955e-01,\n",
              "          1.98683545e-01, -8.32248330e-02,  2.19803438e-01,\n",
              "         -2.18359396e-01,  5.47125220e-01,  4.54025686e-01,\n",
              "          3.17259058e-02,  6.84700370e-01,  3.02212290e-03,\n",
              "         -2.01198965e-01,  4.84217644e-01, -1.66645110e-01,\n",
              "         -4.03287679e-01,  3.59491467e-01,  8.46847117e-01,\n",
              "          4.45403695e-01, -5.76104403e-01, -3.60651851e-01,\n",
              "         -3.82557511e-01, -7.05498308e-02,  3.71364266e-01,\n",
              "         -1.57617033e-01, -6.18019998e-02,  5.92555642e-01,\n",
              "         -8.70550796e-02, -8.72234181e-02, -7.53886282e-01,\n",
              "          5.15462101e-01,  2.37599358e-01, -3.11159551e-01,\n",
              "          2.65788585e-01, -6.27885461e-01,  1.76333711e-01,\n",
              "         -5.60468018e-01, -1.07235529e-01, -1.88623175e-01,\n",
              "          2.20584393e-01,  2.69455850e-01, -9.82136875e-02,\n",
              "          2.72702932e-01,  6.38947189e-01, -4.29419160e-01,\n",
              "         -1.31460026e-01,  4.91113156e-01,  1.03489347e-01,\n",
              "          7.35811964e-02, -2.35272557e-01, -3.68082583e-01,\n",
              "         -5.08661211e-01, -1.87497512e-01,  1.46515667e-05,\n",
              "          4.63933080e-01,  9.30490568e-02, -3.56016904e-01,\n",
              "         -4.61005867e-01, -5.45642316e-01, -1.28861189e-01,\n",
              "         -2.85797387e-01, -3.06000024e-01, -5.85283160e-01,\n",
              "         -3.53170186e-01, -6.64815307e-01,  5.69172382e-01,\n",
              "         -2.14231968e-01, -3.50453019e-01,  1.16309285e-01,\n",
              "         -3.58618557e-01,  2.01009139e-01, -1.78691879e-01,\n",
              "         -8.58891979e-02,  6.48216486e-01,  3.43191475e-01,\n",
              "          3.17217082e-01,  1.16317526e-01, -1.20567091e-01,\n",
              "         -5.38015783e-01,  3.55354190e-01,  5.37198544e-01,\n",
              "         -4.89414096e-01,  4.09816772e-01, -2.92158276e-01,\n",
              "         -4.71087277e-01,  3.39929074e-01, -1.95394069e-01,\n",
              "         -7.35938430e-01,  6.08238220e-01,  7.19562232e-01,\n",
              "          2.16151059e-01,  6.32143855e-01, -3.67439501e-02,\n",
              "         -3.24665338e-01, -3.95948499e-01,  6.18918300e-01,\n",
              "         -6.69315040e-01,  7.55478799e-01, -3.68359476e-01,\n",
              "         -2.12914824e-01,  3.33558023e-01, -4.11469638e-01,\n",
              "         -6.74335182e-01,  2.10593924e-01, -4.12211508e-01,\n",
              "         -4.48239893e-01,  7.33365566e-02, -2.35685542e-01,\n",
              "         -2.40816861e-01,  9.75808725e-02, -9.36741307e-02,\n",
              "          3.24471980e-01, -3.49045515e-01,  3.26951355e-01,\n",
              "          3.19603175e-01, -4.92893249e-01,  3.98766369e-01,\n",
              "         -7.40642995e-02, -5.56625903e-01,  4.61128950e-01,\n",
              "          3.77637953e-01,  3.60686064e-01,  2.68452540e-02,\n",
              "          2.25815147e-01,  2.67445147e-01, -2.73357838e-01,\n",
              "          1.42854571e-01, -2.22056329e-01, -2.49909759e-01,\n",
              "         -4.74702179e-01,  1.30125165e-01,  6.84440911e-01,\n",
              "         -4.15593803e-01, -3.68650705e-01, -2.08287135e-01,\n",
              "          4.06327136e-02,  2.76531577e-01,  2.35001981e-01,\n",
              "         -4.97927777e-02, -3.93381387e-01,  1.90885775e-02,\n",
              "         -2.89373428e-01, -3.36888045e-01, -4.52783614e-01,\n",
              "         -2.44172275e-01,  5.38884401e-01,  2.33517244e-01,\n",
              "         -4.99578178e-01,  2.18645319e-01,  3.58510971e-01,\n",
              "         -7.52573669e-01, -4.07099336e-01, -6.02322519e-01,\n",
              "         -4.47788209e-01, -1.61377296e-01,  4.42276150e-01,\n",
              "          3.52515340e-01,  5.10176480e-01,  5.95225215e-01,\n",
              "         -3.33690196e-01,  3.58795255e-01, -7.28530660e-02,\n",
              "          2.65322268e-01, -3.72890294e-01, -2.18583509e-01,\n",
              "         -7.86654890e-01, -8.51752877e-01,  3.40000354e-02,\n",
              "         -1.64245382e-01, -2.15520561e-01,  2.75119215e-01,\n",
              "         -4.34096418e-02, -4.96937424e-01, -2.26898730e-01,\n",
              "         -3.52692425e-01, -6.43933356e-01,  1.76312730e-01,\n",
              "         -5.46173275e-01, -5.71831644e-01, -1.37960181e-01,\n",
              "         -4.65432763e-01, -8.37596834e-01,  1.87681735e-01,\n",
              "         -4.24356759e-01,  5.49784660e-01,  4.79116619e-01,\n",
              "         -1.78484052e-01, -7.07675993e-01, -3.10084939e-01,\n",
              "         -1.99271902e-01,  8.56645286e-01,  4.16029662e-01,\n",
              "          8.06869566e-02, -3.79935235e-01,  1.66230872e-01,\n",
              "         -1.21521885e-02, -2.54991025e-01,  5.53849280e-01,\n",
              "          7.51932263e-01, -6.55782223e-01, -2.28181571e-01,\n",
              "          8.69744420e-01,  2.32229643e-02,  3.86860460e-01,\n",
              "         -4.26070362e-01, -1.48991030e-02, -5.25660992e-01,\n",
              "         -2.81814188e-01,  1.46991387e-01,  7.52515644e-02,\n",
              "          7.79178381e-01,  1.24075919e-01, -1.24962889e-01,\n",
              "          2.60447323e-01, -5.27475238e-01,  3.32468271e-01,\n",
              "          1.89459547e-01,  3.91328365e-01,  1.35663316e-01,\n",
              "         -6.05128586e-01, -5.20737290e-01, -6.06344700e-01,\n",
              "          5.42048335e-01,  3.22987586e-01, -4.38839525e-01,\n",
              "         -3.04981798e-01,  2.01067090e-01,  2.69076258e-01,\n",
              "         -2.23381847e-01, -9.00583044e-02, -2.58939475e-01,\n",
              "          3.08126748e-01,  7.24121571e-01,  5.81234515e-01,\n",
              "         -4.03206497e-01, -2.88447857e-01,  7.37872779e-01,\n",
              "         -3.65322292e-01, -6.93605766e-02, -4.92191836e-02,\n",
              "          2.61144191e-01,  2.04547852e-01, -1.61046296e-01,\n",
              "          1.91461388e-02, -3.45187962e-01,  2.75882274e-01,\n",
              "         -1.33390918e-01, -4.45000410e-01, -2.76864976e-01,\n",
              "          1.77150801e-01, -3.31577249e-02,  4.63902429e-02,\n",
              "         -9.15514901e-02,  2.03841075e-01,  4.98102546e-01,\n",
              "         -3.57597433e-02, -2.64576316e-01,  1.12101741e-01,\n",
              "          7.85157502e-01,  4.26619768e-01,  6.71297252e-01,\n",
              "         -6.21769667e-01, -6.05829895e-01, -3.57195944e-01,\n",
              "          3.83650362e-01, -4.91275132e-01, -6.41914755e-02,\n",
              "         -2.08032399e-01, -3.35007869e-02, -2.04103664e-01,\n",
              "          5.61134160e-01, -7.26705566e-02,  7.26022869e-02,\n",
              "         -3.15095186e-01,  1.12064620e-02, -6.14724040e-01,\n",
              "         -2.39383429e-01, -2.00100407e-01, -2.89755255e-01,\n",
              "          2.15815857e-01, -6.03415191e-01, -4.37130123e-01,\n",
              "         -1.21581525e-01,  4.29620355e-01, -4.12129551e-01,\n",
              "         -1.38726801e-01,  5.85817337e-01, -3.26292574e-01,\n",
              "          5.58566116e-02, -2.60186434e-01,  7.30555356e-01,\n",
              "         -3.32203507e-02,  4.51502144e-01,  1.82897195e-01,\n",
              "          1.57862306e-01, -4.68141735e-02, -4.28984195e-01,\n",
              "         -8.32309484e-01,  2.75123328e-01, -5.78300714e-01,\n",
              "          3.90297592e-01,  5.11686206e-01,  3.37776281e-02,\n",
              "          1.86176822e-01,  1.97833758e-02, -1.25983745e-01,\n",
              "         -5.66161811e-01, -3.35036904e-01, -7.13450968e-01,\n",
              "         -1.99673861e-01,  3.27759206e-01,  5.27076542e-01,\n",
              "         -3.00939977e-01,  6.46125991e-03,  1.63872480e-01,\n",
              "         -8.58136594e-01, -5.44564724e-01, -2.05164496e-02,\n",
              "         -5.60618222e-01,  8.58413875e-01,  8.06860328e-01,\n",
              "          3.07751328e-01,  3.36630702e-01,  4.34814990e-01,\n",
              "         -3.18203062e-01, -4.88503993e-01, -3.64358664e-01,\n",
              "         -1.55219257e-01,  8.99321586e-02, -2.10816432e-02,\n",
              "         -6.17005587e-01,  1.78063065e-01,  3.46197814e-01,\n",
              "         -6.40685141e-01, -3.56982112e-01,  1.50160745e-01,\n",
              "          2.55935013e-01,  2.42886409e-01,  2.47451873e-03,\n",
              "         -9.68294665e-02, -8.52394402e-02,  4.63572502e-01,\n",
              "         -6.84914351e-01,  3.54435652e-01, -4.93275404e-01,\n",
              "         -7.54510909e-02,  4.09998745e-01, -1.86406195e-01,\n",
              "          1.09227456e-01, -2.55179584e-01, -2.73365587e-01,\n",
              "         -7.31151164e-01,  2.75072813e-01,  8.78914148e-02,\n",
              "          1.17147505e-01, -2.13554502e-01, -1.59876272e-01,\n",
              "         -3.38124782e-01,  1.76946342e-01, -6.53925359e-01,\n",
              "          1.54122069e-01, -1.27309158e-01, -1.29810661e-01,\n",
              "         -4.76168156e-01,  7.43571401e-01, -6.96558356e-02,\n",
              "          4.32079017e-01, -3.21751386e-01, -3.26470673e-01,\n",
              "         -2.48266295e-01, -8.67950916e-02,  2.82303959e-01,\n",
              "          7.74010047e-02, -1.87746137e-01,  3.60253692e-01,\n",
              "         -9.97476652e-02, -4.19435114e-01,  4.93551672e-01,\n",
              "          5.30832827e-01,  5.53632081e-01, -4.95434165e-01,\n",
              "         -4.13876295e-01,  6.58165157e-01,  4.93073016e-01,\n",
              "         -2.22652238e-02,  7.58363664e-01,  1.31382823e-01,\n",
              "         -6.67177022e-01,  4.24922407e-01, -8.27245951e-01,\n",
              "         -1.31288126e-01, -4.94035631e-01, -9.01408568e-02,\n",
              "          7.36651123e-02,  8.98065567e-02,  5.15401542e-01,\n",
              "          3.17143083e-01,  6.74554467e-01, -1.65259331e-01,\n",
              "         -4.20811996e-02, -7.26562619e-01,  4.03104722e-01,\n",
              "          7.24734187e-01,  5.44413850e-02,  2.14062199e-01,\n",
              "         -2.12814912e-01,  1.75894320e-01,  5.10685146e-01,\n",
              "          6.11244142e-01,  1.74058601e-01,  5.27923703e-01,\n",
              "          1.05609618e-01,  3.40759307e-02, -6.08098686e-01]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),\n",
        "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0]]),\n",
        "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
        "}"
      ],
      "metadata": {
        "id": "e8lcUInRSBjM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertBackbone(\n",
        "    vocabulary_size=30000,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    num_groups=1,\n",
        "    num_inner_repetitions=1,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=768,\n",
        "    intermediate_dim=3072,\n",
        "    max_sequence_length=12\n",
        ")"
      ],
      "metadata": {
        "id": "1Od1s8qqTCxh"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_data)"
      ],
      "metadata": {
        "id": "c8MQ0z9hTTap"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySJiyktmTV5O",
        "outputId": "5e0950c9-02ba-4d1c-cbf3-5a652af07e43"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence_output': <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              " array([[[-0.13088837,  0.08823976, -1.2268842 , ...,  2.666011  ,\n",
              "           0.97006965, -0.55991125],\n",
              "         [-0.04050724, -0.3733532 , -1.0165486 , ...,  2.0815506 ,\n",
              "           0.7795344 , -0.7208579 ],\n",
              "         [ 0.52730656, -0.20665151, -1.1171924 , ...,  2.5001056 ,\n",
              "           0.86481845, -0.904895  ],\n",
              "         ...,\n",
              "         [ 0.06860056, -0.45536193, -1.2713169 , ...,  1.5060574 ,\n",
              "           1.3941131 , -0.97114813],\n",
              "         [ 0.14993908, -0.05182786, -1.3196014 , ...,  2.3348632 ,\n",
              "           1.3805138 , -0.4796164 ],\n",
              "         [ 0.6433828 , -0.46940032, -1.1205467 , ...,  2.5178921 ,\n",
              "           0.5583686 , -1.1043622 ]]], dtype=float32)>,\n",
              " 'pooled_output': <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[ 4.78872180e-01, -6.90507233e-01, -6.45176351e-01,\n",
              "         -1.70674026e-01, -6.60097778e-01,  7.55691051e-01,\n",
              "          2.83896327e-01,  7.24015772e-01, -6.89178050e-01,\n",
              "          2.16536373e-01, -2.13252351e-01, -4.15919900e-01,\n",
              "         -4.93452847e-02,  4.03336734e-01, -4.51318532e-01,\n",
              "          5.50888419e-01,  6.86328351e-01,  1.05085112e-01,\n",
              "         -6.86641037e-02, -7.85227306e-03,  3.45604688e-01,\n",
              "         -4.52334642e-01,  4.97773379e-01, -2.24578902e-01,\n",
              "         -6.07672632e-01,  5.09009004e-01,  3.01905006e-01,\n",
              "         -2.46533215e-01, -2.16431245e-01, -3.05556983e-01,\n",
              "          4.94831353e-01,  1.80320740e-01,  1.41678881e-02,\n",
              "          4.59271938e-01,  6.26598060e-01,  4.53835100e-01,\n",
              "         -1.08469818e-02,  1.82795003e-01, -1.31741941e-01,\n",
              "         -4.18417513e-01,  2.99322844e-01,  3.37822586e-01,\n",
              "         -1.88603625e-01,  3.23711812e-01,  2.56297201e-01,\n",
              "          3.34206343e-01, -5.04804134e-01, -2.76128739e-01,\n",
              "         -6.96080804e-01,  4.70822453e-01, -1.26663744e-01,\n",
              "         -4.78852391e-01, -3.69775027e-01, -6.90532267e-01,\n",
              "         -5.61172545e-01, -1.15609646e-01,  9.23926830e-02,\n",
              "         -2.95988172e-01, -3.54987860e-01,  7.54808307e-01,\n",
              "         -6.63385987e-01, -1.93634495e-01, -5.48860133e-01,\n",
              "          2.54024565e-01, -4.45890546e-01,  4.59200256e-02,\n",
              "         -6.03102803e-01,  6.82989955e-01,  2.94238359e-01,\n",
              "          4.26154196e-01, -5.82881868e-01,  6.92685068e-01,\n",
              "          2.27941513e-01, -5.04698269e-02, -5.51293083e-02,\n",
              "         -5.94590664e-01, -7.58754551e-01,  9.88269597e-02,\n",
              "         -5.08009553e-01, -5.42576723e-02,  1.38368934e-01,\n",
              "         -6.67116106e-01, -2.47133002e-01,  3.29423815e-01,\n",
              "          4.18357193e-01, -2.09638536e-01,  2.53724962e-01,\n",
              "          8.20452273e-01, -2.65177101e-01,  6.73636019e-01,\n",
              "         -1.13339782e-01,  4.93176728e-02,  3.62585723e-01,\n",
              "         -3.79252106e-01, -2.62909591e-01,  2.43245408e-01,\n",
              "          4.26775962e-01,  1.55947819e-01,  1.11044809e-01,\n",
              "          4.76678520e-01, -2.64062375e-01,  3.45418230e-05,\n",
              "         -6.50600791e-02,  6.08066201e-01,  3.75630468e-01,\n",
              "         -6.32429242e-01, -2.84172684e-01, -7.56858110e-01,\n",
              "         -2.26847425e-01,  1.50878116e-01,  8.97626802e-02,\n",
              "         -2.53737241e-01,  2.78930604e-01,  3.17059785e-01,\n",
              "          5.61382592e-01, -1.60944134e-01,  3.67606789e-01,\n",
              "          8.00170377e-02,  5.79417944e-01,  3.39538783e-01,\n",
              "         -3.12043786e-01,  4.29553479e-01,  3.88940945e-02,\n",
              "          2.69607514e-01, -4.18648273e-01,  6.55208647e-01,\n",
              "         -8.43316197e-01,  1.76711366e-01,  4.94039834e-01,\n",
              "          1.05279144e-02,  6.11328363e-01,  4.08574969e-01,\n",
              "          5.62137425e-01, -3.93191010e-01,  1.49588019e-01,\n",
              "          3.01737279e-01, -5.26561499e-01, -8.25712264e-01,\n",
              "          5.43893337e-01, -5.67186892e-01, -6.41547203e-01,\n",
              "          3.87766629e-01, -1.83059663e-01, -1.25590771e-01,\n",
              "          3.80083323e-01, -7.35133439e-02,  3.09117496e-01,\n",
              "         -1.37074590e-01,  1.60758704e-01, -2.04558417e-01,\n",
              "         -1.64705113e-01,  2.41685405e-01, -3.56208682e-01,\n",
              "          3.89488041e-01, -1.31900221e-01,  6.23262465e-01,\n",
              "          1.37369588e-01,  5.05822062e-01,  3.57325852e-01,\n",
              "          2.92447656e-01, -6.00273192e-01, -2.68999428e-01,\n",
              "          3.73871714e-01, -1.87865362e-01, -2.64574438e-01,\n",
              "         -3.36585045e-01, -7.60131836e-01,  5.65975547e-01,\n",
              "          7.72265270e-02, -5.49794495e-01,  2.84208059e-01,\n",
              "          3.84233266e-01, -6.13000631e-01,  3.85364026e-01,\n",
              "         -1.01399370e-01,  5.69133535e-02, -4.19174075e-01,\n",
              "         -3.65004241e-01, -2.33212262e-01, -3.21791351e-01,\n",
              "         -1.71840802e-01,  1.21094167e-01, -3.87219153e-02,\n",
              "          6.29341304e-01,  1.19319968e-01, -4.86803383e-01,\n",
              "          3.74013558e-02,  6.34640396e-01, -3.22509795e-01,\n",
              "          7.77230039e-02, -4.02447283e-01, -2.81995177e-01,\n",
              "         -3.85718435e-01,  3.53484482e-01, -9.16170776e-01,\n",
              "         -3.59542549e-01, -7.66471997e-02, -2.12423027e-01,\n",
              "          4.57282290e-02, -1.13415465e-01, -2.59790838e-01,\n",
              "          6.20627739e-02,  1.49135794e-02,  4.74652559e-01,\n",
              "         -2.95012653e-01,  1.65145636e-01,  3.05247843e-01,\n",
              "         -2.05304667e-01,  2.16110244e-01, -4.27449763e-01,\n",
              "         -4.72149774e-02, -4.23094332e-01, -1.71631455e-01,\n",
              "         -7.79297888e-01, -6.44139349e-01,  2.19843283e-01,\n",
              "         -7.17605650e-02, -8.59796330e-02, -3.17824520e-02,\n",
              "         -8.27615499e-01,  7.70583451e-01,  1.19307496e-01,\n",
              "         -4.49596941e-01, -4.63731080e-01,  4.47358817e-01,\n",
              "         -5.84042370e-01, -9.02662128e-02, -3.36448401e-01,\n",
              "         -5.77856600e-01,  5.35946190e-01,  6.43902123e-01,\n",
              "         -1.53661162e-01,  4.95250165e-01, -1.21896408e-01,\n",
              "         -6.51233435e-01, -6.85739875e-01,  1.65682778e-01,\n",
              "         -4.09572721e-01, -9.72268134e-02,  3.40816945e-01,\n",
              "         -9.51944366e-02,  4.04475003e-01, -6.81703746e-01,\n",
              "          6.90250754e-01, -3.00597519e-01, -1.37995467e-01,\n",
              "         -3.29840720e-01, -2.26687744e-01,  3.47619683e-01,\n",
              "          4.39697742e-01, -1.40574202e-01,  6.17595136e-01,\n",
              "         -1.35626778e-01, -4.73705709e-01,  5.41967809e-01,\n",
              "         -3.89431089e-01, -2.03532279e-01, -9.40999612e-02,\n",
              "          7.74398446e-01, -6.58642769e-01, -2.90084124e-01,\n",
              "         -1.76813543e-01,  7.92537928e-01,  5.41455626e-01,\n",
              "         -7.03915000e-01, -4.89444047e-01, -3.14786673e-01,\n",
              "         -1.12127028e-01, -2.00675800e-01,  2.05807328e-01,\n",
              "          5.07731438e-01,  4.11246251e-03,  5.30683041e-01,\n",
              "          1.37923941e-01, -1.30405232e-01, -2.85404056e-01,\n",
              "         -2.67226368e-01,  4.38490123e-01,  1.78835705e-01,\n",
              "         -7.44445994e-02, -7.50575736e-02, -2.84938484e-01,\n",
              "         -4.62654591e-01, -7.33910128e-02, -5.61016440e-01,\n",
              "         -2.46740893e-01,  6.65686429e-01, -8.43835101e-02,\n",
              "         -6.79975808e-01,  5.79097807e-01, -9.34756622e-02,\n",
              "         -4.14069414e-01, -1.47491559e-01,  2.73839563e-01,\n",
              "         -6.34206474e-01,  6.27530873e-01,  9.11372155e-02,\n",
              "         -1.40771210e-01,  6.47614241e-01,  1.55905321e-01,\n",
              "          6.30630672e-01, -6.03709638e-01, -2.35553756e-02,\n",
              "         -5.44968963e-01,  1.41931623e-01, -4.01233882e-01,\n",
              "          1.88794971e-01,  8.00434887e-01, -4.23059583e-01,\n",
              "          3.84126723e-01,  6.42379075e-02,  3.75227392e-01,\n",
              "          5.20401835e-01, -2.18999028e-01, -1.06271654e-01,\n",
              "         -5.41125357e-01,  4.86218035e-02,  3.84286940e-01,\n",
              "          5.27532220e-01,  6.76642656e-01, -3.42994988e-01,\n",
              "         -6.00342117e-02, -3.02917719e-01, -5.20765424e-01,\n",
              "         -2.84708112e-01, -4.09404665e-01,  3.27176154e-01,\n",
              "         -1.25877969e-02,  3.05198133e-01,  2.67759085e-01,\n",
              "         -7.26112008e-01,  8.50880504e-01, -4.16236639e-01,\n",
              "         -8.27027708e-02, -3.40349972e-04,  1.33674532e-01,\n",
              "         -4.26854044e-01,  2.19981924e-01,  6.95633218e-02,\n",
              "         -1.90502286e-01,  3.54275376e-01, -2.09185347e-01,\n",
              "          2.28860185e-01, -3.18227142e-01, -3.42056006e-01,\n",
              "          7.06295133e-01, -6.71317577e-02, -4.57132012e-01,\n",
              "          6.53131157e-02, -5.99157155e-01,  8.95003974e-01,\n",
              "          2.88213462e-01,  4.89467144e-01,  6.44791052e-02,\n",
              "         -1.06250376e-01,  6.38211787e-01, -2.78414756e-01,\n",
              "          1.32242635e-01,  4.66638207e-01,  4.59308743e-01,\n",
              "         -1.71033084e-01,  3.33042324e-01, -7.02838004e-01,\n",
              "          8.55102018e-02,  4.67306882e-01,  5.89672983e-01,\n",
              "         -3.98348272e-01, -3.69194657e-01,  1.90974072e-01,\n",
              "         -3.33124220e-01, -5.72586834e-01, -1.60076514e-01,\n",
              "          2.13459298e-01, -4.15519267e-01, -7.88359225e-01,\n",
              "          3.01641166e-01,  1.16135783e-01,  4.45283689e-02,\n",
              "         -3.37207347e-01, -1.76863089e-01, -3.75172228e-01,\n",
              "         -1.51577204e-01, -9.29916278e-02,  5.36762059e-01,\n",
              "         -2.51190960e-01, -1.68678105e-01, -2.73806781e-01,\n",
              "         -1.89555883e-01, -6.79407597e-01,  2.46033579e-01,\n",
              "          3.52120370e-01, -3.73386711e-01,  4.43012208e-01,\n",
              "          5.68689227e-01,  6.54313207e-01, -2.48052049e-02,\n",
              "          5.35351485e-02,  9.56431851e-02, -6.45525455e-01,\n",
              "         -4.33446728e-02, -7.04056978e-01, -2.57742405e-01,\n",
              "          2.66275167e-01,  8.51167664e-02,  5.61478972e-01,\n",
              "         -3.52451444e-01,  2.44937479e-01,  1.40571278e-02,\n",
              "          2.57669806e-01, -2.82120168e-01,  1.68317869e-01,\n",
              "         -5.02239168e-01, -3.01978946e-01,  5.56948543e-01,\n",
              "         -3.35139199e-03, -3.68661322e-02,  6.19670510e-01,\n",
              "          5.13353229e-01, -1.60357282e-01, -1.68122277e-01,\n",
              "         -2.32643753e-01,  5.32780170e-01, -2.44497478e-01,\n",
              "         -3.59319389e-01,  3.25904906e-01,  3.65669340e-01,\n",
              "          3.81270647e-01,  3.44007760e-01,  3.20673168e-01,\n",
              "         -1.12052038e-01,  5.91761708e-01,  2.90792614e-01,\n",
              "          1.18760370e-01,  1.50152355e-01,  7.81277478e-01,\n",
              "          2.65160203e-01, -4.13068794e-02,  7.43095398e-01,\n",
              "          4.98297632e-01, -4.35288221e-01,  3.49684328e-01,\n",
              "          4.54724550e-01, -4.07031000e-01, -1.14494957e-01,\n",
              "         -7.08920956e-01,  8.39690343e-02, -5.14861643e-01,\n",
              "         -5.29553369e-02, -7.03481555e-01, -8.61900628e-01,\n",
              "          4.40133125e-01,  5.27022958e-01, -2.68715233e-01,\n",
              "          4.61650342e-01,  3.71145099e-01, -3.43215764e-01,\n",
              "          6.38602376e-01, -5.03570974e-01, -2.91704774e-01,\n",
              "          1.87699512e-01,  6.63286150e-01, -4.79874104e-01,\n",
              "          4.49407399e-01, -2.17735887e-01,  2.69319594e-01,\n",
              "          7.35859051e-02, -5.75767040e-01, -1.38726309e-01,\n",
              "          4.65033725e-02,  1.97917134e-01,  6.57129467e-01,\n",
              "         -3.81082773e-01,  5.43535292e-01,  5.30690730e-01,\n",
              "         -3.21698725e-01,  3.39693576e-01,  4.47955690e-02,\n",
              "          3.46218407e-01,  4.66958284e-01, -8.81286152e-03,\n",
              "         -3.86042953e-01, -1.56883270e-01, -1.19625665e-02,\n",
              "          1.22159772e-01, -6.79123700e-02,  6.93371594e-02,\n",
              "         -1.27060294e-01,  1.81576550e-01,  5.09231627e-01,\n",
              "         -3.86095941e-01,  3.91644657e-01, -4.38113689e-01,\n",
              "         -3.96217644e-01,  6.62710071e-01, -1.05315551e-01,\n",
              "          1.44704059e-01, -6.16111159e-01,  6.15345061e-01,\n",
              "         -1.58672258e-01, -4.88504589e-01, -3.93914478e-03,\n",
              "          5.02086639e-01, -2.89933771e-01, -4.77648765e-01,\n",
              "         -1.18681818e-01, -8.20165694e-01, -1.55546367e-01,\n",
              "         -6.40894696e-02, -1.59396231e-01, -8.38548720e-01,\n",
              "         -2.82368392e-01, -1.66862354e-01, -7.36766696e-01,\n",
              "          1.53612733e-01,  3.39832097e-01,  2.49497682e-01,\n",
              "         -7.98069775e-01,  6.21363580e-01, -4.61767197e-01,\n",
              "          5.53319514e-01,  6.48104846e-01,  5.56375623e-01,\n",
              "          6.09979272e-01,  3.19857866e-01, -9.38400269e-01,\n",
              "         -1.30772414e-02, -1.39004961e-01, -1.38709292e-01,\n",
              "         -3.25521499e-01, -7.76724041e-01,  5.82376957e-01,\n",
              "         -4.11808908e-01, -5.17925978e-01,  1.09512113e-01,\n",
              "         -4.08229619e-01,  9.16774105e-03,  1.33611977e-01,\n",
              "          3.30595464e-01,  2.88143367e-01, -2.12014109e-01,\n",
              "          3.07453036e-01,  3.03243518e-01, -7.34611899e-02,\n",
              "         -2.48673633e-01, -8.06231797e-02,  5.26634812e-01,\n",
              "          7.30325341e-01, -2.60388911e-01, -6.60304129e-02,\n",
              "         -2.38195717e-01,  1.33807078e-01,  3.39432329e-01,\n",
              "          8.96728560e-02,  3.93821537e-01,  1.53113186e-01,\n",
              "          5.58184445e-01,  2.24147320e-01, -1.59900472e-01,\n",
              "         -5.80349922e-01,  8.80093873e-02,  4.14819896e-01,\n",
              "          2.79845804e-01,  8.56548399e-02,  3.26746285e-01,\n",
              "          7.09964484e-02, -4.70511496e-01, -4.00564641e-01,\n",
              "         -2.57402718e-01,  3.35463434e-01, -5.87027550e-01,\n",
              "         -2.14576125e-01, -8.31494391e-01, -8.01607966e-01,\n",
              "         -4.94706869e-01, -5.67197859e-01,  6.16291277e-02,\n",
              "         -1.86375365e-01, -6.89155459e-02, -1.76823154e-01,\n",
              "          3.58330280e-01, -4.34837341e-01,  2.29746252e-01,\n",
              "         -1.73984781e-01,  5.20020537e-02, -4.41501290e-01,\n",
              "         -2.74854571e-01,  9.36605632e-02, -1.17075495e-01,\n",
              "          1.90980449e-01,  2.53403425e-01, -5.36258757e-01,\n",
              "         -1.02437928e-01, -1.93743512e-01,  6.76512063e-01,\n",
              "         -2.21680030e-01,  3.57471257e-02, -4.00815874e-01,\n",
              "         -9.66238305e-02,  2.20748454e-01, -9.73642394e-02,\n",
              "         -3.56762916e-01,  4.56205904e-02, -6.61901951e-01,\n",
              "          2.22013518e-01,  4.76723820e-01, -2.18731210e-01,\n",
              "         -5.29041648e-01, -1.11042738e-01, -6.38179600e-01,\n",
              "         -2.00421661e-01,  4.53479797e-01, -6.96637809e-01,\n",
              "          1.20277308e-01, -8.13855752e-02, -2.78463781e-01,\n",
              "          1.01123638e-01,  5.26305556e-01, -5.10468483e-01,\n",
              "         -3.40664536e-01, -3.90595853e-01, -8.17794442e-01,\n",
              "          1.73179179e-01, -3.79822880e-01,  2.62556732e-01,\n",
              "          7.97751665e-01,  3.78112197e-01, -1.61828607e-01,\n",
              "         -1.12901986e-01, -2.17311874e-01,  2.30057359e-01,\n",
              "         -3.57847780e-01,  2.47954592e-01, -5.94270408e-01,\n",
              "         -1.88975379e-01, -1.49862990e-01, -3.04719448e-01,\n",
              "          5.21176040e-01, -2.67986089e-01, -1.97391450e-01,\n",
              "          2.03814313e-01,  4.94890988e-01,  6.59330130e-01,\n",
              "         -5.48669174e-02,  2.19513640e-01,  6.20229132e-02,\n",
              "          4.69802946e-01,  5.14829099e-01, -4.01642501e-01,\n",
              "          2.36513972e-01, -4.35181074e-02,  6.81550324e-01,\n",
              "          3.56673509e-01,  2.80505240e-01,  9.73450467e-02,\n",
              "          4.03450310e-01, -3.65853190e-01,  7.65609443e-01,\n",
              "          4.30037051e-01, -1.92445651e-01, -2.69572794e-01,\n",
              "         -1.12628624e-01,  1.90238476e-01,  4.61604804e-01,\n",
              "         -2.99878299e-01,  7.77773738e-01,  4.72910613e-01,\n",
              "         -2.16799840e-01, -3.46733660e-01,  4.57903706e-02,\n",
              "         -1.29225329e-01,  4.25299436e-01, -5.25613844e-01,\n",
              "          3.54649752e-01, -6.64624631e-01, -5.84727764e-01,\n",
              "          1.70453951e-01,  5.38879931e-02,  1.03975713e-01,\n",
              "          7.69221932e-02, -1.83323666e-01, -7.53745556e-01,\n",
              "          1.01565637e-01,  1.84932098e-01,  1.23115838e-01,\n",
              "          1.36077091e-01, -2.28897795e-01, -6.06329367e-02,\n",
              "          1.08638607e-01,  1.30087465e-01,  2.55185574e-01,\n",
              "         -7.87244886e-02, -3.69304299e-01, -3.62500459e-01,\n",
              "          5.21199524e-01,  3.06083113e-01,  4.91888016e-01,\n",
              "         -7.35405803e-01, -2.00597763e-01,  4.12516236e-01,\n",
              "          2.20219623e-02, -5.93934894e-01,  1.25271544e-01,\n",
              "         -2.43299365e-01, -5.13633013e-01, -6.47066593e-01,\n",
              "          5.60557961e-01,  2.02192515e-01, -4.76158082e-01,\n",
              "          6.01646155e-02,  3.53540748e-01, -2.59469330e-01,\n",
              "          2.55215913e-01,  7.11902916e-01,  1.00890048e-01,\n",
              "          3.75041932e-01,  1.03754170e-01,  5.48466921e-01,\n",
              "          6.14217579e-01, -2.36121550e-01,  5.19948117e-02,\n",
              "          6.02738634e-02, -3.13344479e-01, -6.07774615e-01,\n",
              "         -6.35981798e-01,  3.55704278e-01,  5.39345145e-01,\n",
              "          9.64251440e-03,  3.37734222e-01, -3.10381949e-01,\n",
              "          1.94800004e-01,  6.50881410e-01, -5.06123185e-01,\n",
              "          1.01960443e-01,  7.73192227e-01, -1.81934938e-01,\n",
              "          5.15231431e-01, -9.12736952e-02, -6.20302320e-01,\n",
              "          2.50232190e-01,  4.43394452e-01,  4.25744772e-01,\n",
              "          4.13898319e-01,  9.89455655e-02, -1.49943486e-01,\n",
              "          8.26804340e-01,  4.10498053e-01, -8.37567002e-02,\n",
              "          2.79466331e-01, -7.21117705e-02, -5.97959291e-03,\n",
              "          4.55818951e-01,  6.10958695e-01, -3.97014320e-01,\n",
              "          2.77345031e-01,  3.45078558e-01,  4.87005413e-02,\n",
              "          5.07753678e-02,  2.70277739e-01, -4.64142531e-01,\n",
              "          7.85886705e-01, -5.92646599e-01, -3.54933888e-01,\n",
              "          9.24681500e-03,  5.71396828e-01, -1.66696042e-01,\n",
              "          1.25353530e-01,  8.23351979e-01, -2.20202506e-01]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = {\n",
        "    \"token_ids\": np.ones(shape=(1, 12), dtype=\"int32\"),\n",
        "    \"segment_ids\": np.array([[0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0]]),\n",
        "    \"padding_mask\": np.array([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0]])\n",
        "}"
      ],
      "metadata": {
        "id": "vMWKPLgnTWve"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AlbertBackbone(\n",
        "    vocabulary_size=40000,\n",
        "    num_layers=12,\n",
        "    num_heads=12,\n",
        "    num_groups=1,\n",
        "    num_inner_repetitions=1,\n",
        "    embedding_dim=128,\n",
        "    hidden_dim=768,\n",
        "    intermediate_dim=3072,\n",
        "    max_sequence_length=12\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "W6rlHw7z9Ogf"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(input_data)"
      ],
      "metadata": {
        "id": "fWxwjY6_9jqE"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxMzxfPr9mx5",
        "outputId": "4cc0dd29-0b75-4f4b-c85f-201230df4f58"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sequence_output': <tf.Tensor: shape=(1, 12, 768), dtype=float32, numpy=\n",
              " array([[[-0.75534403, -0.75417334,  0.33269697, ..., -1.4872432 ,\n",
              "          -0.02140048,  0.3107443 ],\n",
              "         [-0.7471708 , -1.1808239 ,  0.37219864, ..., -1.0479399 ,\n",
              "           0.20953861,  0.5745775 ],\n",
              "         [-0.8838515 , -0.8517772 ,  0.8287881 , ..., -1.3643435 ,\n",
              "          -0.23354311,  0.29294768],\n",
              "         ...,\n",
              "         [-1.2791067 , -1.4830219 ,  0.3637959 , ..., -0.80328214,\n",
              "           0.24591447,  0.17525207],\n",
              "         [-0.93527675, -1.0091276 ,  0.1830863 , ..., -0.6074742 ,\n",
              "          -0.31253108,  0.27885374],\n",
              "         [-0.66678584, -1.4363064 ,  0.46831828, ..., -1.1809998 ,\n",
              "          -0.37692195,  0.2886842 ]]], dtype=float32)>,\n",
              " 'pooled_output': <tf.Tensor: shape=(1, 768), dtype=float32, numpy=\n",
              " array([[ 3.37796539e-01, -3.70496154e-01,  5.03299654e-01,\n",
              "          2.66553372e-01, -3.42828691e-01, -1.12798244e-01,\n",
              "         -4.27170098e-02,  7.26790607e-01, -2.89803326e-01,\n",
              "          1.64868310e-01, -3.12318206e-01,  1.22563958e-01,\n",
              "         -1.90847084e-01,  1.51209459e-01,  1.76601395e-01,\n",
              "         -1.44221455e-01, -7.35381842e-02,  4.46943909e-01,\n",
              "         -6.18263125e-01,  6.92805767e-01, -1.93623677e-01,\n",
              "         -2.26848260e-01, -4.32428777e-01,  5.38179874e-01,\n",
              "         -4.00327981e-01, -4.24179673e-01,  1.13954738e-01,\n",
              "          7.91388273e-01,  4.39635187e-01, -3.15995924e-02,\n",
              "         -2.77648240e-01, -4.83199388e-01,  1.90119565e-01,\n",
              "          1.18037775e-01, -3.58496159e-01,  2.10860908e-01,\n",
              "          3.33561599e-02, -3.54066715e-02, -3.73699844e-01,\n",
              "         -7.02585042e-01,  2.00005159e-01,  4.10467803e-01,\n",
              "         -2.47349963e-01, -2.78261065e-01, -1.64947823e-01,\n",
              "         -2.62545377e-01,  4.48281854e-01,  3.60576689e-01,\n",
              "          5.52589357e-01, -2.27825433e-01,  6.50220394e-01,\n",
              "          2.50687808e-01, -4.85683858e-01, -6.92675352e-01,\n",
              "         -2.32860148e-01,  4.92201179e-01, -3.97035837e-01,\n",
              "          2.11757272e-01,  5.84668100e-01, -4.43995118e-01,\n",
              "         -1.40031993e-01, -3.41217011e-01, -1.70512408e-01,\n",
              "         -2.82077491e-01,  8.03018987e-01, -2.13654727e-01,\n",
              "          8.33130181e-02,  5.76129258e-01,  5.44216782e-02,\n",
              "          8.40836287e-01, -2.05452874e-01, -6.84803128e-01,\n",
              "          1.71681792e-01, -7.53518939e-01, -5.21797180e-01,\n",
              "         -2.13814467e-01, -3.51691455e-01,  3.26085463e-02,\n",
              "         -3.72994810e-01, -4.36076224e-02, -1.51485711e-01,\n",
              "          3.87105972e-01,  6.72837377e-01,  8.17508250e-02,\n",
              "         -6.90600395e-01,  2.64397532e-01, -7.15346396e-01,\n",
              "          6.53143466e-01, -7.20872283e-01,  2.68555701e-01,\n",
              "          5.23172557e-01, -8.14623296e-01,  1.98000163e-01,\n",
              "          4.02451098e-01,  3.34133089e-01,  6.00629337e-02,\n",
              "         -2.53686011e-01,  2.97702253e-01,  2.77861774e-01,\n",
              "         -5.76221049e-02, -3.80743206e-01,  1.58498093e-01,\n",
              "         -3.35428864e-01, -7.01562345e-01, -4.53727484e-01,\n",
              "          3.76020968e-01, -3.08351189e-01, -7.30421990e-02,\n",
              "          6.79887593e-01,  2.79523164e-01,  4.87633348e-02,\n",
              "          6.04872227e-01, -2.38588616e-01, -1.47367328e-01,\n",
              "          7.85440505e-02,  5.34417629e-01, -4.86930087e-02,\n",
              "         -5.59785306e-01,  4.66183349e-02,  5.77929318e-01,\n",
              "          3.43639642e-01, -6.13472350e-02, -6.90016448e-02,\n",
              "          5.18277526e-01,  5.42879879e-01, -8.68639816e-03,\n",
              "          7.25877166e-01,  5.28446555e-01, -5.44538945e-02,\n",
              "          7.19933733e-02,  5.65346122e-01,  5.43424666e-01,\n",
              "          4.55244146e-02, -3.53454888e-01, -9.42367092e-02,\n",
              "         -4.20786768e-01, -1.63355812e-01,  6.15037084e-01,\n",
              "          5.78517169e-02, -4.16224897e-01, -4.88764465e-01,\n",
              "         -3.49421084e-01,  4.88767296e-01, -3.63007933e-01,\n",
              "         -4.20256615e-01, -5.55741131e-01, -4.51968789e-01,\n",
              "          1.32360160e-01,  5.72930694e-01, -1.63959458e-01,\n",
              "          4.30736095e-01, -4.38429862e-01,  2.85296082e-01,\n",
              "         -2.03967884e-01,  6.87154531e-01, -5.20520568e-01,\n",
              "         -5.15414253e-02, -7.35720620e-02,  4.68793601e-01,\n",
              "         -3.33424546e-02, -4.04209405e-01,  1.06345527e-01,\n",
              "          5.14879525e-01,  5.22656202e-01, -5.84589422e-01,\n",
              "         -4.85679179e-01, -4.64537203e-01,  5.92026830e-01,\n",
              "         -1.94012925e-01,  4.32125717e-01,  2.06085995e-01,\n",
              "         -2.12792065e-02, -2.86037445e-01, -3.64450723e-01,\n",
              "          7.05169499e-01, -4.69681710e-01,  1.35665163e-01,\n",
              "          5.24961948e-01,  2.98036814e-01,  1.63548604e-01,\n",
              "          1.56579122e-01,  4.15174931e-01,  1.48735747e-01,\n",
              "         -4.22366709e-01,  4.29007292e-01, -7.52396584e-01,\n",
              "          2.68728644e-01,  1.12074567e-03,  2.74224460e-01,\n",
              "          2.22231284e-01,  5.42891741e-01,  2.37518787e-01,\n",
              "         -1.76207468e-01,  3.10557872e-01,  1.73761278e-01,\n",
              "         -5.92778563e-01, -4.67536777e-01, -6.96645558e-01,\n",
              "          5.03407657e-01, -4.82192896e-02, -1.50400430e-01,\n",
              "          5.34999967e-01,  4.32630837e-01, -6.92719996e-01,\n",
              "         -3.61056000e-01,  5.65196611e-02,  8.24578404e-01,\n",
              "          4.67244424e-02, -2.21271425e-01, -2.84259915e-01,\n",
              "          1.82444021e-01,  3.02786350e-01,  6.11932814e-01,\n",
              "         -3.15995336e-01, -2.22400837e-02, -2.35381469e-01,\n",
              "         -2.23669291e-01, -1.13370903e-02,  6.92359746e-01,\n",
              "          1.21152252e-01,  1.27215490e-01, -4.10438478e-01,\n",
              "          2.64740318e-01, -5.83050400e-02, -2.71429211e-01,\n",
              "         -3.64760198e-02,  1.16932869e-01, -1.70620412e-01,\n",
              "          2.77579039e-01, -3.28997970e-01, -9.46578681e-02,\n",
              "         -2.56659776e-01, -1.88846424e-01, -6.21051073e-01,\n",
              "          8.58494937e-01,  5.57464659e-01,  4.49007988e-01,\n",
              "         -3.88585657e-01, -3.77025247e-01, -5.83033323e-01,\n",
              "          4.98316377e-01,  7.13395298e-01, -7.85647392e-01,\n",
              "         -1.22975454e-01, -4.78057891e-01, -4.95483100e-01,\n",
              "          6.83694482e-01,  7.88439691e-01, -4.40831959e-01,\n",
              "          7.29012340e-02,  4.76466566e-01,  3.11927766e-01,\n",
              "         -2.63037741e-01,  3.56930554e-01,  3.76861915e-02,\n",
              "         -2.91900843e-01,  2.43590623e-01, -4.27489996e-01,\n",
              "         -6.93341136e-01,  6.30630016e-01,  6.86324611e-02,\n",
              "          1.60169303e-01, -4.11077350e-01,  5.98521411e-01,\n",
              "         -7.63282716e-01,  3.29672277e-01, -2.16579571e-01,\n",
              "         -6.79290354e-01, -9.02303606e-02,  1.12923414e-01,\n",
              "          6.46231920e-02, -6.25989854e-01, -4.31104332e-01,\n",
              "          4.91538018e-01,  2.67629623e-01, -4.97958392e-01,\n",
              "         -1.08273283e-01,  2.24948972e-01, -1.34748826e-02,\n",
              "         -2.81289876e-01,  1.34885907e-01,  1.71481911e-02,\n",
              "         -1.47747472e-01, -3.44322741e-01,  1.45651430e-01,\n",
              "         -4.31552120e-02,  3.94935906e-01,  7.50800490e-01,\n",
              "          4.54222351e-01,  2.13378463e-02, -7.74573565e-01,\n",
              "          7.39130378e-01, -8.80215287e-01,  6.06744170e-01,\n",
              "         -3.13589983e-02,  3.11787695e-01, -5.61225533e-01,\n",
              "          2.63859600e-01, -1.87474236e-01, -5.02969027e-01,\n",
              "          6.78372085e-02,  4.14520115e-01,  4.50469166e-01,\n",
              "          2.35277951e-01, -1.98790744e-01,  1.80427358e-01,\n",
              "          1.56043231e-01,  1.42970502e-01, -1.81107968e-02,\n",
              "         -2.84274787e-01,  5.94491102e-02,  1.52316108e-01,\n",
              "          2.54396290e-01,  4.63675231e-01, -4.31870490e-01,\n",
              "          5.78458488e-01, -3.72421086e-01, -2.97338545e-01,\n",
              "          3.69500488e-01,  7.57240832e-01, -2.43523955e-01,\n",
              "         -3.42699319e-01, -1.19138442e-01,  5.42384207e-01,\n",
              "          9.61927846e-02,  1.44482076e-01,  2.46836141e-01,\n",
              "          7.15675414e-01,  2.44196400e-01, -3.92218292e-01,\n",
              "          5.50914705e-01,  2.99244821e-01, -2.40769684e-01,\n",
              "         -3.32336366e-01, -1.01354674e-01, -2.61601359e-01,\n",
              "          8.51229250e-01, -1.24704391e-02, -7.73668885e-01,\n",
              "         -3.07120718e-02, -3.64200532e-01, -5.95597982e-01,\n",
              "          5.95217705e-01, -5.30528843e-01,  7.27423012e-01,\n",
              "         -1.22353956e-01,  3.10670197e-01, -5.33510208e-01,\n",
              "         -2.13637590e-01,  2.75613397e-01,  4.96177413e-02,\n",
              "         -6.77815676e-01,  2.67588168e-01, -1.64787844e-01,\n",
              "          1.67623803e-01, -1.88942328e-02,  7.14742422e-01,\n",
              "         -5.82744062e-01,  1.53993711e-01, -1.90767214e-01,\n",
              "         -3.98977041e-01,  8.75007063e-02, -2.58199722e-01,\n",
              "          9.88183469e-02, -3.17501634e-01,  6.04042828e-01,\n",
              "         -2.36429200e-01,  3.15693706e-01,  1.46184787e-01,\n",
              "         -6.14004076e-01,  8.04718852e-01,  5.07109165e-01,\n",
              "         -6.76080406e-01,  2.40798682e-01, -8.14564645e-01,\n",
              "         -7.29248077e-02, -1.78297535e-02, -5.61726809e-01,\n",
              "         -1.88460294e-02,  3.82062048e-01,  3.79159927e-01,\n",
              "         -5.12133718e-01,  5.27988732e-01, -8.70621741e-01,\n",
              "         -7.99320817e-01,  1.13163404e-01, -1.98454916e-01,\n",
              "         -5.62598884e-01, -5.11468887e-01, -4.52234000e-01,\n",
              "          5.03581529e-03,  3.21303546e-01, -3.41947764e-01,\n",
              "          4.76591624e-02, -1.64792791e-01, -2.51309991e-01,\n",
              "          6.13273680e-01, -8.06904852e-01, -1.00072585e-01,\n",
              "         -7.63076246e-01, -3.79189610e-01,  5.17747179e-02,\n",
              "         -7.41745770e-01, -2.92855385e-03,  1.94405079e-01,\n",
              "         -3.89090389e-01,  2.01788947e-01,  3.06115657e-01,\n",
              "         -3.78746331e-01, -3.50330502e-01, -2.78952777e-01,\n",
              "          1.61583632e-01,  4.29397542e-03, -7.67700449e-02,\n",
              "          3.00647825e-01,  4.88665521e-01,  8.51777568e-03,\n",
              "         -3.45871001e-01, -8.50883365e-01, -1.49325624e-01,\n",
              "         -6.60870254e-01,  6.66444540e-01,  4.59303737e-01,\n",
              "         -9.66347829e-02,  4.35299486e-01,  1.98060289e-01,\n",
              "         -7.79660702e-01,  2.82874197e-01, -6.04482234e-01,\n",
              "          8.70042592e-02, -1.44496426e-01, -4.78239387e-01,\n",
              "         -6.81155920e-01, -4.39440608e-01,  2.20005617e-01,\n",
              "          4.62395251e-02, -2.82220870e-01,  1.47616729e-01,\n",
              "         -6.59678280e-01, -4.10707921e-01, -8.50807190e-01,\n",
              "          3.86560768e-01,  1.46177024e-01,  2.17557281e-01,\n",
              "          1.40460923e-01, -4.60509844e-02, -7.18935207e-02,\n",
              "          1.58210203e-01, -5.96565366e-01,  1.12384126e-01,\n",
              "          8.15544128e-02, -8.10489058e-01,  1.46408498e-01,\n",
              "         -4.68814433e-01, -5.67318439e-01,  2.19350949e-01,\n",
              "         -5.19401133e-02,  8.23764384e-01, -2.75502324e-01,\n",
              "         -1.11506812e-01, -3.33153784e-01, -1.65517494e-01,\n",
              "         -3.95212650e-01, -6.42039716e-01,  3.32372159e-01,\n",
              "          2.68561780e-01, -5.49659908e-01,  5.77781349e-02,\n",
              "         -3.03468555e-01,  3.67689192e-01, -3.46940815e-01,\n",
              "          1.98714465e-01, -5.72563708e-01, -4.38257009e-01,\n",
              "          5.11519074e-01, -1.23815229e-02, -3.50864828e-01,\n",
              "         -3.44282463e-02,  7.35276416e-02,  6.36180937e-01,\n",
              "          3.64848137e-01, -9.02124643e-02,  2.06985608e-01,\n",
              "          3.34085852e-01, -4.87697631e-01,  3.60044688e-01,\n",
              "         -6.82781935e-02, -5.28586805e-01,  6.79003119e-01,\n",
              "          2.54690468e-01, -1.12877868e-01,  3.35574597e-01,\n",
              "          2.21144691e-01,  2.72482425e-01,  5.36702037e-01,\n",
              "          5.69126964e-01, -3.97895753e-01, -7.89470796e-04,\n",
              "          2.48803318e-01,  5.12622297e-01,  2.99250722e-01,\n",
              "          8.60529542e-01,  1.08019948e-01,  1.70504838e-01,\n",
              "          2.49576136e-01, -3.59011203e-01,  6.71803713e-01,\n",
              "         -3.63135397e-01, -5.68577871e-02,  8.17251801e-01,\n",
              "         -1.00241326e-01, -3.67851257e-01,  3.77852350e-01,\n",
              "         -3.05212557e-01,  1.35361299e-01,  1.09286696e-01,\n",
              "         -6.94488883e-01, -2.65972495e-01, -3.59631479e-01,\n",
              "         -4.08144087e-01, -1.31882310e-01,  3.17759156e-01,\n",
              "          2.63798833e-01,  1.73062533e-01, -3.13753933e-01,\n",
              "         -4.51963454e-01, -1.16091939e-02, -4.95565772e-01,\n",
              "         -9.06381235e-02,  3.23043793e-01, -3.70802172e-02,\n",
              "          3.40850443e-01,  9.87096429e-02,  2.82337703e-02,\n",
              "         -2.59404123e-01, -2.11292177e-01,  2.46979013e-01,\n",
              "          3.92722398e-01,  6.79340780e-01,  1.49679869e-01,\n",
              "          5.97894669e-01, -1.23758398e-01,  6.95386410e-01,\n",
              "         -5.14395475e-01,  6.70571774e-02, -2.27326557e-01,\n",
              "         -5.49301244e-02,  5.00458598e-01, -7.87639201e-01,\n",
              "         -6.26767218e-01, -4.83935595e-01,  1.69682547e-01,\n",
              "          2.32445344e-01,  3.60097796e-01,  2.49556616e-01,\n",
              "         -1.44750327e-01, -2.27882817e-01, -8.30282211e-01,\n",
              "         -4.18537438e-01,  1.05119392e-01,  4.04434800e-01,\n",
              "          1.25557050e-01, -7.35794902e-01,  6.70442760e-01,\n",
              "         -2.61264443e-01,  8.23130384e-02,  9.64208916e-02,\n",
              "         -5.80475815e-02, -6.16157413e-01, -5.01280427e-01,\n",
              "          3.15457940e-01, -7.12768137e-01, -4.41892654e-01,\n",
              "         -1.89552829e-01,  5.32554448e-01,  1.56555206e-01,\n",
              "         -9.67924446e-02, -1.46583706e-01,  8.80096480e-03,\n",
              "         -7.93912768e-01, -1.56776190e-01,  1.73727632e-01,\n",
              "          6.35804772e-01,  2.92081386e-01, -9.69192982e-02,\n",
              "         -3.52386892e-01,  5.54338872e-01,  4.54077929e-01,\n",
              "         -1.26482293e-01,  5.31256735e-01,  7.30020523e-01,\n",
              "          4.72923666e-01, -7.37915099e-01,  4.48415160e-01,\n",
              "          4.91200626e-01, -4.58014399e-01,  3.34470063e-01,\n",
              "         -2.49730065e-01, -4.50725734e-01,  1.26771018e-01,\n",
              "          5.86040616e-01, -4.47875977e-01,  5.92729568e-01,\n",
              "          1.91553637e-01,  3.29182923e-01,  7.73430109e-01,\n",
              "          4.40488532e-02, -4.30414557e-01, -5.16300976e-01,\n",
              "         -6.41671002e-01, -1.31189719e-01, -1.15974605e-01,\n",
              "         -5.32285213e-01, -1.21894337e-01, -2.16102496e-01,\n",
              "         -3.21839988e-01,  6.73227429e-01, -1.38139352e-01,\n",
              "          2.77964294e-01, -5.79522431e-01, -4.53898668e-01,\n",
              "         -7.56719410e-01,  4.26135570e-01, -5.47115803e-01,\n",
              "         -1.65088624e-02,  1.51503589e-02,  7.04109967e-01,\n",
              "         -1.33019209e-01,  7.21896768e-01, -1.66110039e-01,\n",
              "         -6.26766205e-01, -7.69980028e-02,  4.82832402e-01,\n",
              "         -2.90440381e-01,  5.61547697e-01, -1.96939424e-01,\n",
              "         -1.19637586e-01, -5.93856990e-01, -7.03314126e-01,\n",
              "         -5.46112061e-01, -5.61766215e-02, -5.58479726e-01,\n",
              "         -6.71066880e-01,  3.82524431e-01,  2.82839149e-01,\n",
              "          3.50227356e-01, -3.85290504e-01, -2.63628244e-01,\n",
              "         -1.59416258e-01, -2.99432904e-01, -1.29183173e-01,\n",
              "         -5.71618378e-01, -1.32175297e-01, -2.58987427e-01,\n",
              "         -3.69160742e-01,  3.01645786e-01,  3.80341113e-02,\n",
              "          1.24139503e-01, -5.12601435e-01, -2.19290629e-01,\n",
              "          1.06107444e-04, -3.42128038e-01, -2.07004130e-01,\n",
              "          4.39033031e-01,  3.96558493e-01,  7.94240013e-02,\n",
              "         -2.37449810e-01,  3.03349763e-01,  4.64463860e-01,\n",
              "         -4.92091507e-01, -9.57076788e-01, -1.67729855e-01,\n",
              "         -8.75918567e-02,  1.63393706e-01,  2.96219233e-02,\n",
              "         -3.21507640e-02,  6.84620738e-02, -6.43223464e-01,\n",
              "          2.87075222e-01, -6.36354268e-01,  1.68496042e-01,\n",
              "         -1.45259127e-01,  1.54308334e-01, -6.27056122e-01,\n",
              "         -4.85559367e-02,  1.33556455e-01, -6.34764314e-01,\n",
              "         -3.78777266e-01, -1.03824675e-01, -5.82725585e-01,\n",
              "         -4.56341237e-01,  3.91850978e-01, -1.93982884e-01,\n",
              "         -3.57240409e-01,  5.55780768e-01, -3.26788008e-01,\n",
              "          5.99656045e-01,  6.38776004e-01, -4.02419060e-01,\n",
              "         -4.65253383e-01, -3.32274199e-01, -6.71974897e-01,\n",
              "         -5.19735277e-01, -1.54917851e-01,  3.68113488e-01,\n",
              "          1.33727401e-01,  7.52081051e-02,  1.00219965e-01,\n",
              "          8.48869145e-01,  4.81511354e-01, -5.95473230e-01,\n",
              "          3.40585470e-01, -2.89029360e-01,  7.94527531e-02,\n",
              "         -1.30521700e-01, -8.14803839e-02,  5.87752104e-01,\n",
              "         -1.30449235e-01,  2.72435188e-01, -6.20029449e-01,\n",
              "         -2.03425273e-01,  3.31741005e-01, -3.81855220e-02,\n",
              "         -4.66917157e-01,  5.24879456e-01, -1.24213219e-01,\n",
              "          5.40669143e-01, -4.23860371e-01, -4.79210526e-01,\n",
              "         -6.29288077e-01, -4.50234748e-02, -7.12024271e-01,\n",
              "          2.16326550e-01,  3.89900416e-01, -2.55938143e-01,\n",
              "          2.50094324e-01, -1.18170537e-01,  1.88741490e-01,\n",
              "          8.40998709e-01, -3.26427370e-01,  4.30236459e-01,\n",
              "          5.54942429e-01, -4.01171952e-01,  6.42697990e-01,\n",
              "          5.45243323e-01,  6.67771876e-01, -6.90484405e-01,\n",
              "         -1.93651468e-01, -2.29348525e-01,  3.34256381e-01,\n",
              "         -6.29086316e-01,  4.62587625e-01,  7.51846969e-01,\n",
              "         -4.21239883e-02, -3.77850235e-01,  9.42537338e-02,\n",
              "          1.99897006e-01, -4.54455972e-01,  5.05899310e-01,\n",
              "          5.55512309e-01,  1.73799679e-01, -3.57007869e-02,\n",
              "          3.73207003e-01,  7.30253935e-01, -1.70249399e-02,\n",
              "         -5.60947776e-01,  1.59176335e-01, -4.70825493e-01]], dtype=float32)>}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_nlp.models import AlbertClassifier"
      ],
      "metadata": {
        "id": "_GZ1X-o09nu7"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features = [\"The quick brown fox jumped.\", \"I forgot my homework.\"]\n",
        "labels = [0, 3]"
      ],
      "metadata": {
        "id": "tvp0N1yO-qna"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pretrained classifier\n",
        "classifier = AlbertClassifier.from_preset(\"albert_base_en_uncased\", num_classes=4,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DFm5KzsT_Poa",
        "outputId": "f40da611-84a6-4853-d63a-13903b0a4dbd"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n",
            "/usr/local/lib/python3.10/dist-packages/keras_nlp/src/models/backbone.py:37: UserWarning: `layer.updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  return id(getattr(self, attr)) not in self._functional_layer_ids\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.fit(x=features, y=labels, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0wGZz-mD_Z3A",
        "outputId": "d8251b3e-ae9f-44a0-8517-6055e6d2bf33"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 59s 59s/step - loss: 1.0710 - sparse_categorical_accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7af161d49090>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classifier.predict(x=features, batch_size=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUNxhVFn_4zC",
        "outputId": "179be0e7-5d8c-49ff-b195-6b8c8b911957"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 12s 12s/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.36460766, -0.75142205, -0.86742896, -0.08825801],\n",
              "       [-0.16667296, -0.8212894 , -1.0983584 ,  0.33867338]],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1GPyPqqz_gEi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}